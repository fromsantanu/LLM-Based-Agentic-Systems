# **Chapter 4. Building Blocks of Agentic AI**

Agentic AI systems are modular by design. They are not built as monolithic blocks but as flexible pipelines composed of smaller components that can interact, learn, and adapt. In LangChain, the foundation of these systems is made up of **chains, tools, prompts, and agents**.

This chapter will introduce the essential building blocks you’ll use repeatedly when creating agentic workflows.

---

## 4.1 Creating Simple Chains

Chains are sequences of steps where the output of one component becomes the input to the next. The simplest chain is an **LLMChain**, where a prompt is passed to a Large Language Model (LLM), and the model returns a response.

### LLMChain

```python
from langchain_openai import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

llm = OpenAI(model="gpt-3.5-turbo")

prompt = PromptTemplate.from_template("What are three key health benefits of {exercise}?")

chain = LLMChain(llm=llm, prompt=prompt)

print(chain.run("yoga"))
```

Here:

* **PromptTemplate** defines a reusable template with placeholders.
* **LLMChain** connects the prompt to the model.
* `chain.run()` executes the workflow.

### SequentialChain

When tasks require multiple dependent steps, you can use a **SequentialChain**.

```python
from langchain.chains import SequentialChain

# First step: generate an exercise name
prompt1 = PromptTemplate.from_template("Suggest a physical activity for improving heart health.")
chain1 = LLMChain(llm=llm, prompt=prompt1, output_key="exercise")

# Second step: describe benefits
prompt2 = PromptTemplate.from_template("Explain the benefits of {exercise} in 100 words.")
chain2 = LLMChain(llm=llm, prompt=prompt2, output_key="benefits")

overall_chain = SequentialChain(
    chains=[chain1, chain2],
    input_variables=[],
    output_variables=["exercise", "benefits"]
)

print(overall_chain.run({}))
```

Sequential chains allow **pipeline-style reasoning**, perfect for multi-step tasks like text summarization → sentiment analysis → decision-making.

---

## 4.2 Adding Tools

Agents need external **tools** to act in the world beyond their language capabilities. LangChain provides integrations for many tools, but you can also define your own.

### Common Tools

* **Python REPL** – run Python code safely in a sandbox.
* **Web Search** – query online search engines.
* **Calculator** – perform numerical calculations.

```python
from langchain.agents import load_tools
from langchain.agents import initialize_agent

tools = load_tools(["python_repl", "serpapi", "llm-math"], llm=llm)
```

Here:

* `python_repl` enables code execution.
* `serpapi` (or other connectors) enables web search.
* `llm-math` provides a calculator for numerical reasoning.

---

## 4.3 Designing Prompts for Tool-Use

Prompts must guide the model to know *when and how* to use tools. Without instructions, the model might try to “hallucinate” answers instead of invoking the tool.

Example tool-use prompt:

```
You are a helpful assistant with access to the following tools:
- Python REPL for calculations
- Web Search for up-to-date information

If a user asks something requiring calculation, use Python.
If a user asks for current facts, use Web Search.
```

This explicit guidance reduces confusion and ensures correct tool invocation.

---

## 4.4 Agents with Tool-Calling Abilities

Unlike static chains, **agents** dynamically decide:

* Which tool to call
* In what order
* When to stop and respond

### Example: Zero-Shot Agent

```python
from langchain.agents import AgentType

agent = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True
)

agent.run("What is the square root of 245 times 3?")
```

Here:

* The **Zero-Shot ReAct Agent** uses reasoning traces to decide whether to call the calculator or return an answer directly.
* The process is dynamic, not pre-defined like in a SequentialChain.

---

## 4.5 Routing Between Different Chains

In complex applications, different types of requests may require different chains. **Chain routing** ensures the input is directed to the correct workflow.

### Example: Router Chain

```python
from langchain.chains.router import MultiPromptChain, RouterChain
from langchain.prompts import PromptTemplate

# Define specialized prompts
science_prompt = PromptTemplate.from_template("Explain {topic} for a high school student.")
history_prompt = PromptTemplate.from_template("Tell a short story about {topic} in history.")

destination_chains = {
    "science": LLMChain(llm=llm, prompt=science_prompt),
    "history": LLMChain(llm=llm, prompt=history_prompt),
}

router_chain = MultiPromptChain(
    llm=llm,
    destination_chains=destination_chains,
    default_chain=LLMChain(llm=llm, prompt=PromptTemplate.from_template("Talk about {topic}."))
)

print(router_chain.run("photosynthesis"))
```

Here, the system routes "photosynthesis" to the **science chain**, while a history-related query would be sent to the **history chain**.

---

## ✅ Key Takeaways

1. **Chains** provide structured pipelines (LLMChain, SequentialChain).
2. **Tools** extend the agent’s ability beyond text (Python, Calculator, Web Search).
3. **Prompts** must be carefully designed to encourage correct tool use.
4. **Agents** dynamically decide which tools or chains to call.
5. **Routing** directs user queries to the most appropriate chain.

Together, these building blocks form the **core infrastructure of agentic AI**, enabling models not only to *think* but also to *act* intelligently.

---

