
# **Chapter 2: Python Foundations for LangChain**

Before we dive deep into building agentic systems with LangChain, we must establish a solid Python foundation. This chapter focuses on setting up your environment, managing dependencies, installing essential libraries, and handling API keys securely.

---

## 2.1 Setting up Python Environment

LangChain projects often involve multiple dependencies, so isolating them in a dedicated environment is a best practice. There are two common ways to manage environments:

### Using `venv`

```bash
# Create a virtual environment
python -m venv langchain-env

# Activate it
# On Linux/MacOS:
source langchain-env/bin/activate
# On Windows:
langchain-env\Scripts\activate

# Verify activation
which python
```

### Using Conda

```bash
# Create a new environment with Python 3.11
conda create -n langchain-env python=3.11 -y

# Activate environment
conda activate langchain-env
```

> **Tip**: Stick to Python 3.10+ for compatibility with most AI libraries.

---

## 2.2 Installing Dependencies

Once your environment is ready, install the required libraries:

```bash
pip install langchain openai chromadb qdrant-client faiss-cpu python-dotenv
```

* `langchain` – Core framework for building LLM-powered applications.
* `openai` – Client for OpenAI’s models (e.g., GPT, embeddings).
* `chromadb` – Local vector database for semantic search and RAG.
* `qdrant-client` – Client for Qdrant, a scalable vector DB.
* `faiss-cpu` – Facebook’s library for fast vector similarity search.
* `python-dotenv` – To manage environment variables from `.env` files.

> If you plan to work with GPUs, you can install `faiss-gpu` instead of `faiss-cpu`.

---

## 2.3 Essential Python Libraries for Agentic AI

Here’s a quick overview of the role each library plays in agentic workflows:

| Library       | Purpose                                                           |
| ------------- | ----------------------------------------------------------------- |
| **LangChain** | Framework to connect LLMs, tools, memory, and agents.             |
| **OpenAI**    | API client for using GPT models (chat, completion, embeddings).   |
| **ChromaDB**  | Local vector store for RAG pipelines, fast and simple.            |
| **Qdrant**    | Cloud/local vector DB, scalable with advanced filtering & search. |
| **FAISS**     | High-performance similarity search library for embeddings.        |
| **dotenv**    | Keeps API keys and configs secure by loading from `.env` files.   |

---

## 2.4 Working with `.env` and API Keys Securely

When working with APIs like OpenAI, you’ll need to store sensitive credentials. **Never hardcode keys directly in your code.** Instead, use environment variables.

### Step 1: Create a `.env` File

In your project root, create a file named `.env`:

```
OPENAI_API_KEY=your_openai_api_key_here
QDRANT_API_KEY=your_qdrant_api_key_here
```

### Step 2: Load with `dotenv`

```python
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()

# Access API keys
openai_key = os.getenv("OPENAI_API_KEY")
qdrant_key = os.getenv("QDRANT_API_KEY")

print("OpenAI Key:", openai_key[:5] + "****")  # Masked for safety
```

### Step 3: Use in LangChain

```python
from langchain_openai import OpenAI

llm = OpenAI(api_key=openai_key)
response = llm.invoke("Hello, what is Agentic AI?")
print(response)
```

> **Security Tip**:
>
> * Add `.env` to your `.gitignore` so it never gets pushed to GitHub.
> * Rotate keys if they’re ever exposed.

---

✅ **By the end of this chapter, you have:**

* A clean Python environment (venv/conda).
* Installed all essential libraries for Agentic AI.
* Set up secure `.env` handling for API keys.

In the next chapter, we’ll begin building **LangChain primitives** (models, prompts, memory, and chains) that form the backbone of agentic systems.

---
