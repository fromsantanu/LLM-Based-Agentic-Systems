*Lesson 7: Running RQ Worker**

---

### **1. Installing and Configuring RQ Worker**

Before you can run a background worker, ensure the **Redis Queue (RQ)** package is installed and your environment is set up correctly.

```bash
pip install rq
```

In your FastAPI project, you should already have a **Redis connection** defined (for example, in `redis_conn.py`):

```python
# redis_conn.py
from redis import Redis
redis_conn = Redis(host="localhost", port=6379, db=0)
```

To make sure your worker can access the same Redis connection and task functions, you’ll typically have a **`worker.py`** file like this:

```python
# worker.py
import os
from rq import Worker, Queue, Connection
from redis_conn import redis_conn

listen = ['default']  # list of queues to listen to

if __name__ == '__main__':
    with Connection(redis_conn):
        worker = Worker(map(Queue, listen))
        worker.work()
```

This script connects to Redis and starts listening to the `"default"` queue.

---

### **2. Running RQ Worker from CLI**

Run the RQ worker in your terminal using the following command:

```bash
rq worker
```

If you want to specify the queue name explicitly:

```bash
rq worker default
```

To check information about jobs and queues:

```bash
rq info
```

To monitor queue activity in real time:

```bash
rq info --interval 2
```

You can also use **`rq-dashboard`** (optional but recommended) for a web interface:

```bash
pip install rq-dashboard
rq-dashboard
```

It runs at: **[http://127.0.0.1:9181](http://127.0.0.1:9181)**

---

### **3. Understanding the Job Lifecycle**

Each job in RQ goes through a clear **lifecycle**:

| **Stage**    | **Description**                                       |
| ------------ | ----------------------------------------------------- |
| **Queued**   | Job has been enqueued but not yet picked by a worker. |
| **Started**  | Worker has begun executing the job function.          |
| **Finished** | Job completed successfully.                           |
| **Failed**   | Job execution raised an exception.                    |

You can inspect these states programmatically:

```python
from rq.job import Job

job = Job.fetch('your_job_id', connection=redis_conn)
print(job.get_status())  # queued, started, finished, or failed
```

---

### **4. Example Workflow**

1. **Submit a job** from FastAPI:

   ```python
   job = q.enqueue(process_message, message="Hello")
   ```
2. **Run the worker**:

   ```bash
   rq worker
   ```
3. **Check job status**:

   ```python
   job.get_status()
   job.result
   ```
4. **Monitor through CLI or dashboard**:

   ```bash
   rq info
   rq-dashboard
   ```

---

### ✅ **Summary**

* `rq worker` starts the background worker.
* `rq info` shows queue and job statistics.
* `rq-dashboard` provides a real-time UI.
* Job states: **queued → started → finished → failed**.
* Workers must run continuously in the background to process tasks.

---

