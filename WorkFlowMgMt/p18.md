# Lesson 18: Building a Mini Workflow Engine

**End-to-end app: FastAPI + Redis RQ**
**Pattern:** Submit → Queue → Worker → Status → Result
**Plus:** Persistent logs & Prometheus metrics

---

## 1) Learning goals

* Design a minimal yet production-lean **workflow API** with FastAPI + RQ.
* Implement the core flow: **/submit → enqueue → process in worker → /status → /result**.
* Persist **job logs/metadata** and expose **metrics** for monitoring.

---

## 2) Architecture (mental model)

```
Client → FastAPI (/submit) ──enqueue──▶ Redis (queue)
Client ← /status ────────────┐
Client ← /result ────────────┘
                RQ Worker ◀─── pulls job from Redis, runs task, pushes result/status
                └─▶ Logs (file + SQLite) & Metrics (/metrics, RQ stats)
```

---

## 3) Project scaffold

```
mini-workflow/
├─ app/
│  ├─ main.py                # FastAPI app + routes + metrics
│  ├─ config.py              # settings from .env
│  ├─ redis_conn.py          # Redis connection + RQ Queue helpers
│  ├─ tasks.py               # worker task(s)
│  ├─ workers/
│  │  └─ rq_worker.py        # RQ worker entry
│  ├─ logging_conf.py        # logging + file rotation
│  ├─ models.py              # SQLite models: JobLog, JobMeta
│  ├─ db.py                  # SQLAlchemy engine/session
│  └─ metrics.py             # Prometheus counters/histograms + middleware
├─ requirements.txt
├─ .env.example
├─ docker-compose.yml        # redis + api + worker (optional)
└─ README.md
```

**requirements.txt**

```
fastapi
uvicorn[standard]
python-dotenv
redis
rq
pydantic
sqlalchemy
prometheus-client
```

**.env.example**

```
REDIS_URL=redis://localhost:6379/0
QUEUE_NAME=default
LOG_DIR=./logs
DB_URL=sqlite:///./workflow.db
APP_PORT=8000
```

---

## 4) Config, DB & logging

**app/config.py**

```python
from pydantic import BaseSettings

class Settings(BaseSettings):
    REDIS_URL: str = "redis://localhost:6379/0"
    QUEUE_NAME: str = "default"
    LOG_DIR: str = "./logs"
    DB_URL: str = "sqlite:///./workflow.db"
    APP_PORT: int = 8000

    class Config:
        env_file = ".env"

settings = Settings()
```

**app/db.py**

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from .config import settings

engine = create_engine(settings.DB_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)
Base = declarative_base()
```

**app/models.py**

```python
from sqlalchemy import Column, String, Text, DateTime, Integer
from sqlalchemy.sql import func
from .db import Base

class JobMeta(Base):
    __tablename__ = "job_meta"
    job_id = Column(String, primary_key=True, index=True)
    status = Column(String, index=True)         # queued/started/finished/failed
    task_name = Column(String, index=True)
    created_at = Column(DateTime, server_default=func.now())
    finished_at = Column(DateTime, nullable=True)
    result_preview = Column(String, nullable=True)  # short summary

class JobLog(Base):
    __tablename__ = "job_log"
    id = Column(Integer, primary_key=True, autoincrement=True)
    job_id = Column(String, index=True)
    level = Column(String, index=True)
    message = Column(Text)
    ts = Column(DateTime, server_default=func.now(), index=True)
```

**app/logging_conf.py**

```python
import logging, os
from logging.handlers import RotatingFileHandler
from .config import settings

def setup_logging():
    os.makedirs(settings.LOG_DIR, exist_ok=True)
    log_path = os.path.join(settings.LOG_DIR, "app.log")

    fmt = "[%(asctime)s] %(levelname)s %(name)s: %(message)s"
    logging.basicConfig(level=logging.INFO, format=fmt)

    fh = RotatingFileHandler(log_path, maxBytes=5_000_000, backupCount=3)
    fh.setFormatter(logging.Formatter(fmt))
    root = logging.getLogger()
    root.addHandler(fh)
```

---

## 5) Redis & RQ

**app/redis_conn.py**

```python
import redis
from rq import Queue
from .config import settings

_redis = redis.from_url(settings.REDIS_URL)
queue = Queue(settings.QUEUE_NAME, connection=_redis)

def get_queue() -> Queue:
    return queue
```

**app/workers/rq_worker.py**

```python
# Run with:  rq worker -u <REDIS_URL> <QUEUE_NAME>
# or python -m app.workers.rq_worker (see README for options)
# File kept for clarity; actual RQ CLI is preferred.
```

---

## 6) Prometheus metrics

**app/metrics.py**

```python
import time
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST

REQ_COUNTER = Counter("api_requests_total", "Total API requests", ["method","path","status"])
REQ_LATENCY = Histogram("api_request_latency_seconds", "Latency", ["method","path"])
JOBS_ENQUEUED = Counter("jobs_enqueued_total", "Jobs enqueued", ["task"])
JOBS_FINISHED = Counter("jobs_finished_total", "Jobs finished", ["task"])
JOBS_FAILED = Counter("jobs_failed_total", "Jobs failed", ["task"])

async def metrics_endpoint():
    data = generate_latest()
    return data, CONTENT_TYPE_LATEST

def metrics_middleware():
    async def middleware(request, call_next):
        start = time.time()
        response = await call_next(request)
        elapsed = time.time() - start
        path = request.url.path
        REQ_COUNTER.labels(request.method, path, str(response.status_code)).inc()
        REQ_LATENCY.labels(request.method, path).observe(elapsed)
        return response
    return middleware
```

---

## 7) The task & worker-side logging

**app/tasks.py**

```python
import logging, json, datetime as dt
from rq import get_current_job
from sqlalchemy.orm import Session
from .db import SessionLocal
from .models import JobLog, JobMeta
from .metrics import JOBS_FINISHED, JOBS_FAILED

logger = logging.getLogger("tasks")

def _log(db: Session, job_id: str, level: str, msg: str):
    db.add(JobLog(job_id=job_id, level=level, message=msg))
    db.commit()

def example_task(payload: dict) -> dict:
    """Pretend long-running task."""
    job = get_current_job()
    job_id = job.id if job else "unknown"
    db = SessionLocal()

    try:
        _log(db, job_id, "INFO", f"Started processing payload keys={list(payload.keys())}")
        # do some work
        text = payload.get("text", "")
        tokens = len(text.split())
        result = {"uppercase": text.upper(), "token_count": tokens}
        _log(db, job_id, "INFO", f"Computed result={json.dumps(result)[:200]}")

        # update JobMeta.finished_at, result_preview
        jm = db.get(JobMeta, job_id)
        if jm:
            jm.finished_at = dt.datetime.utcnow()
            jm.result_preview = json.dumps(result)[:200]
            jm.status = "finished"
            db.commit()
        JOBS_FINISHED.labels("example_task").inc()
        return result

    except Exception as e:
        _log(db, job_id, "ERROR", f"Task failed: {e}")
        jm = db.get(JobMeta, job_id)
        if jm:
            jm.status = "failed"
            db.commit()
        JOBS_FAILED.labels("example_task").inc()
        raise
    finally:
        db.close()
```

---

## 8) FastAPI app (routes: submit/status/result/metrics)

**app/main.py**

```python
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse, PlainTextResponse
from pydantic import BaseModel
import logging
from .config import settings
from .logging_conf import setup_logging
from .redis_conn import get_queue
from .tasks import example_task
from .db import Base, engine, SessionLocal
from .models import JobMeta
from .metrics import metrics_endpoint, metrics_middleware, JOBS_ENQUEUED

setup_logging()
Base.metadata.create_all(bind=engine)

app = FastAPI(title="Mini Workflow Engine")
app.middleware("http")(metrics_middleware())  # latency & counters

class SubmitIn(BaseModel):
    task: str = "example_task"
    payload: dict

@app.get("/health")
def health():
    return {"ok": True}

@app.post("/submit")
def submit_job(body: SubmitIn):
    if body.task != "example_task":
        raise HTTPException(status_code=400, detail="Unknown task")

    q = get_queue()
    job = q.enqueue(example_task, body.payload)
    # persist meta
    db = SessionLocal()
    try:
        jm = JobMeta(job_id=job.id, status="queued", task_name=body.task)
        db.add(jm); db.commit()
    finally:
        db.close()

    JOBS_ENQUEUED.labels(body.task).inc()
    logging.getLogger("api").info(f"Enqueued job_id={job.id} task={body.task}")
    return {"job_id": job.id}

@app.get("/status/{job_id}")
def job_status(job_id: str):
    q = get_queue()
    job = q.fetch_job(job_id)
    if not job:
        # try DB (if worker finished and RQ cleaned)
        db = SessionLocal(); jm = db.get(JobMeta, job_id); db.close()
        if jm:
            return {"job_id": job_id, "status": jm.status}
        raise HTTPException(404, "Job not found")

    status_map = {
        None: "queued",
        "queued": "queued",
        "started": "started",
        "finished": "finished",
        "failed": "failed"
    }
    stat = job.get_status()
    # sync DB status
    db = SessionLocal()
    try:
        jm = db.get(JobMeta, job_id)
        if jm and jm.status != stat:
            jm.status = stat; db.commit()
    finally:
        db.close()

    return {"job_id": job_id, "status": status_map.get(stat, stat)}

@app.get("/result/{job_id}")
def job_result(job_id: str):
    q = get_queue()
    job = q.fetch_job(job_id)
    if job and job.is_finished:
        return {"job_id": job_id, "result": job.result}

    # fallback to DB preview if job cleaned up
    db = SessionLocal()
    try:
        jm = db.get(JobMeta, job_id)
        if jm and jm.status == "finished" and jm.result_preview:
            return {"job_id": job_id, "result_preview": jm.result_preview}
    finally:
        db.close()

    raise HTTPException(404, "Result not available yet")

@app.get("/metrics")
def metrics():
    data, content_type = metrics_endpoint()
    return PlainTextResponse(content=data, media_type=content_type)
```

---

## 9) Running locally

```bash
# 1) Redis
docker run -p 6379:6379 redis:7

# 2) Python env
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt
cp .env.example .env

# 3) API
uvicorn app.main:app --reload --port 8000

# 4) Worker (separate terminal)
# Uses RQ CLI (recommended)
export REDIS_URL=redis://localhost:6379/0
rq worker -u $REDIS_URL default
# (Windows PowerShell)  rq worker -u redis://localhost:6379/0 default
```

---

## 10) Try it out (cURL)

```bash
# Submit
curl -X POST http://localhost:8000/submit \
  -H "Content-Type: application/json" \
  -d '{"task":"example_task","payload":{"text":"Hello mini workflow engine"}}'

# Suppose response: {"job_id":"<ID>"}
JOB=<paste-id>

# Status
curl http://localhost:8000/status/$JOB

# Result
curl http://localhost:8000/result/$JOB

# Metrics
curl http://localhost:8000/metrics
```

---

## 11) Persistent logs & job history (how it works)

* **App/worker logs** go to `logs/app.log` with rotation (5 MB × 3 files).
* **Per-job structured logs** are written into SQLite table `job_log`.
* **Job metadata** (status, timestamps, result preview) is stored in `job_meta`.
* **Metrics**:

  * `api_requests_total{method,path,status}`
  * `api_request_latency_seconds{method,path}`
  * `jobs_enqueued_total{task}`
  * `jobs_finished_total{task}`
  * `jobs_failed_total{task}`

You can scrape `/metrics` with Prometheus and visualize in Grafana.
RQ queue depth/worker state come from `rq worker` CLI or **RQ Dashboard** (see Lesson 17).

---

## 12) Optional: docker-compose (all-in-one)

**docker-compose.yml**

```yaml
version: "3.9"
services:
  redis:
    image: redis:7
    ports: ["6379:6379"]

  api:
    build: .
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DB_URL=sqlite:////data/workflow.db
      - LOG_DIR=/data/logs
    volumes:
      - ./data:/data
    depends_on: [redis]
    ports: ["8000:8000"]

  worker:
    build: .
    command: rq worker -u redis://redis:6379/0 default
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on: [redis]
```

> Add a minimal `Dockerfile` if you plan to use compose (Python base, copy code, install deps).

---

## 13) Testing checklist

* Submit multiple jobs; ensure **/status** transitions: queued → started → finished.
* Kill worker mid-run; confirm **/status** and DB reflect **failed** or **stuck** appropriately.
* Check `logs/app.log` and `SELECT * FROM job_log WHERE job_id=...`.
* Hit `/metrics`; ensure counters move as you call endpoints and jobs complete/fail.
* If using RQ Dashboard (Lesson 17), verify queue depth and job details.

---

## 14) Troubleshooting

* **Job not found:** worker not running or different queue name—match `QUEUE_NAME`.
* **Result empty:** job still running or cleaned; check DB `result_preview`.
* **Redis connection error:** correct `REDIS_URL`, ensure port 6379 reachable.
* **Permissions on SQLite/logs:** ensure app can write to `LOG_DIR` & DB path.

---

## 15) Extensions (homework)

* Add **/logs/{job_id}** to stream/paginate JobLog.
* Implement **retries** and **retry-after** headers (see Lesson 16).
* Add **request_id** correlation (header → logs/metrics labels).
* Expose **/stats** combining Redis (queue size) + DB (throughput per hour).
* Switch to **structlog** for JSON logs; ship to Loki/ELK in production.

---

### What you have now

A compact, production-lean **mini workflow engine** that:

* Queues work with **Redis RQ**
* Processes asynchronously via **workers**
* Exposes **status** and **result** endpoints
* Persists **logs & metadata** to SQLite
* Publishes **Prometheus metrics** at `/metrics`



