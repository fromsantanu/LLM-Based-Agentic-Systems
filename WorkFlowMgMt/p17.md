# **Lesson 17: Deployment and Monitoring**

### ðŸŽ¯ **Objective**

Learn how to deploy your workflow system (FastAPI + Redis + RQ/ARQ) in production, monitor task queues, and scale workers for higher performance and reliability.

---

### **1. Running Workers in Production**

When moving from development to production, youâ€™ll need to ensure that your **FastAPI app** and **worker processes** start automatically and restart on failure.

#### **Option 1: Using systemd (Linux servers)**

Create a unit file (e.g., `/etc/systemd/system/rq-worker.service`):

```ini
[Unit]
Description=RQ Worker
After=network.target

[Service]
User=ubuntu
Group=ubuntu
WorkingDirectory=/home/ubuntu/app
Environment="REDIS_URL=redis://localhost:6379/0"
ExecStart=/home/ubuntu/.venv/bin/rq worker --url $REDIS_URL default
Restart=always

[Install]
WantedBy=multi-user.target
```

Then run:

```bash
sudo systemctl daemon-reload
sudo systemctl enable rq-worker
sudo systemctl start rq-worker
sudo systemctl status rq-worker
```

#### **Option 2: Using Docker Compose**

Example `docker-compose.yml`:

```yaml
version: "3.8"

services:
  fastapi:
    build: .
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis

  worker:
    build: .
    command: rq worker --url redis://redis:6379/0 default
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

Start the stack:

```bash
docker-compose up -d
```

---

### **2. Using RQ Dashboard for Job Monitoring**

RQ provides a simple web-based dashboard to view:

* Job queues
* Running and failed jobs
* Worker status

Install and run it:

```bash
pip install rq-dashboard
rq-dashboard
```

By default, it runs at:
ðŸ‘‰ **[http://localhost:9181](http://localhost:9181)**

You can also embed it inside your FastAPI/Docker environment:

```yaml
dashboard:
  image: eoranged/rq-dashboard
  environment:
    - RQ_DASHBOARD_REDIS_URL=redis://redis:6379/0
  ports:
    - "9181:9181"
  depends_on:
    - redis
```

**Alternative for ARQ:**
If using **ARQ**, you can build a simple custom `/metrics` route in FastAPI that reports queue lengths or recent job results.

---

### **3. Scaling Horizontally with Multiple Workers**

To handle more jobs concurrently:

#### **Multiple worker processes:**

```bash
rq worker high medium low &
rq worker default &
```

You can assign queues by priority.

#### **Multiple worker containers:**

In Docker Compose, scale your worker service:

```bash
docker-compose up --scale worker=3 -d
```

Each worker listens to the same Redis queue, allowing distributed job execution.

#### **Redis Configuration Tips:**

* Use **Redis persistence** (`appendonly yes`) for reliability.
* Monitor Redis memory usage and configure eviction policy (`volatile-lru` or `allkeys-lru`).

---

### **4. Monitoring and Logging**

Use a combination of:

* **RQ Dashboard** for queue visualization
* **FastAPI logs** for request/job submissions
* **Worker logs** (stdout or files) for debugging
* **Prometheus + Grafana** (optional advanced setup) for metrics visualization

Example log redirection in Docker:

```yaml
worker:
  build: .
  command: rq worker default
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
```

---

### âœ… **Summary**

| Topic               | Description                                            |
| ------------------- | ------------------------------------------------------ |
| **systemd**         | Manage worker lifecycle on Linux                       |
| **Docker Compose**  | Containerized deployment of app + Redis + worker       |
| **RQ Dashboard**    | Web interface to monitor job queues                    |
| **Scaling Workers** | Run multiple workers to process tasks concurrently     |
| **Monitoring**      | Combine RQ dashboard, logs, and metrics for visibility |

---

### ðŸš€ **Next Step**

Proceed to **Lesson 18: Performance Optimization and Best Practices** â€” where weâ€™ll cover job batching, caching, and optimizing Redis usage for high-load systems.

---
