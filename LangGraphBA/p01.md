# Chapter 1: What is LangGraph?

LangGraph is a **framework for building stateful, multi-agent workflows** on top of [LangChain](https://www.langchain.com/).
Where LangChain provides the **building blocks** (LLM wrappers, chains, tools, retrievers, memory modules, etc.), LangGraph focuses on **orchestration** ‚Äî defining how agents, tools, and workflows interact with each other over time.

In simple terms:

* **LangChain** = Toolbox for LLM apps (chains, prompts, tools, retrievers).
* **LangGraph** = Blueprint for **stateful agent orchestration** (control flow, looping, branching, recovery).

---

## Concept of Stateful Agent Orchestration

A **stateful system** remembers what happened before, instead of starting fresh with each request.

* In LangChain, memory is often ‚Äúper-call‚Äù or requires you to wire up special memory modules.
* In LangGraph, the **graph itself maintains state** as the workflow progresses.

This means:

* Agents can **pause, resume, or loop**.
* Workflows can **branch based on conditions** (e.g., if a diagnostic agent flags ‚Äúhigh risk,‚Äù send patient data to a specialist agent).
* Long-running tasks can continue across multiple interactions without losing context.

---

## Key Differences Between LangChain and LangGraph

| Feature          | LangChain                              | LangGraph                                                     |
| ---------------- | -------------------------------------- | ------------------------------------------------------------- |
| Primary Role     | Build pipelines (chains) for LLM tasks | Orchestrate multi-agent workflows                             |
| State Management | Requires explicit memory modules       | Built-in state tracking at graph level                        |
| Flow Control     | Mostly sequential or custom Python     | Native graph model: branching, looping, conditional execution |
| Error Handling   | Minimal, manual retries                | Structured recovery & re-routing                              |
| Best For         | Simple apps (chatbots, RAG pipelines)  | Complex apps (triage systems, agentic workflows, simulations) |

---

## Example: LangChain Sequential Chain vs. LangGraph Workflow

### 1. LangChain Sequential Chain

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import SimpleSequentialChain

llm = OpenAI()

# Step 1: Generate an idea
prompt1 = PromptTemplate.from_template("Suggest a title for a story about {topic}.")
chain1 = prompt1 | llm

# Step 2: Expand into a story
prompt2 = PromptTemplate.from_template("Write a short story with the title: {title}.")
chain2 = prompt2 | llm

# Sequential chain
overall_chain = SimpleSequentialChain(chains=[chain1, chain2])

print(overall_chain.run("a robot learning emotions"))
```

üîπ Here, the flow is **linear**: input ‚Üí title ‚Üí story. No branching, no state tracking beyond this single run.

---

### 2. LangGraph Workflow

```python
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI

# Define state
class StoryState(dict):
    topic: str
    title: str
    story: str

# LLM
llm = ChatOpenAI(model="gpt-4o-mini")

# Define nodes
def generate_title(state: StoryState):
    result = llm.invoke(f"Suggest a title for a story about {state['topic']}")
    state["title"] = result.content
    return state

def expand_story(state: StoryState):
    result = llm.invoke(f"Write a short story titled '{state['title']}'")
    state["story"] = result.content
    return state

# Create graph
graph = StateGraph(StoryState)
graph.add_node("title", generate_title)
graph.add_node("story", expand_story)

# Define edges
graph.set_entry_point("title")
graph.add_edge("title", "story")
graph.add_edge("story", END)

app = graph.compile()

# Run
final_state = app.invoke({"topic": "a robot learning emotions"})
print(final_state["story"])
```

üîπ Here, the flow is **stateful and flexible**:

* Each step updates the state (`topic`, `title`, `story`).
* You can add branching, e.g., ‚Äúif title too short ‚Üí regenerate.‚Äù
* You can pause/resume at any node.

---

‚úÖ **Takeaway:**

* **LangChain** = easy entry point for simple LLM pipelines.
* **LangGraph** = robust orchestration for **multi-step, stateful, agentic systems**.

---

