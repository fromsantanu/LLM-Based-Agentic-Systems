# Chapter 15: Retries & Fallbacks

When building robust agent workflows, it‚Äôs not enough to just handle the *happy path*. Models and tools can fail ‚Äî sometimes because of network errors, invalid outputs, or timeouts. **Retries** and **fallbacks** allow you to gracefully recover from these errors and keep your graph reliable.

---

## üîπ Key Ideas

1. **Retries**

   * Re-run a node if it fails due to an exception, timeout, or invalid output.
   * Often combined with limits (e.g., retry up to 3 times).
   * Useful for transient errors (e.g., API connection drops).

2. **Fallbacks**

   * Define an alternate node or path if the primary node fails.
   * Ensures that the workflow doesn‚Äôt break completely.
   * Useful for ensuring *minimum viable output* (e.g., using regex parsing if LLM parsing fails).

3. **When to Use Which**

   * **Retries**: When failure is temporary and likely to succeed on reattempt.
   * **Fallbacks**: When failure is due to limitations of the main node (e.g., LLM struggling with structured extraction).

---

## üõ†Ô∏è Example: LLM ‚Üí Regex Backup

Imagine you want to extract a date from text.

* Primary node: LLM (semantic extraction).
* Fallback: Regex (pattern-based).

```python
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
import re

# Define state
class State(dict):
    text: str
    date: str | None

# Nodes
llm = ChatOpenAI(model="gpt-4o-mini")

def extract_with_llm(state: State):
    prompt = f"Extract the date mentioned in: {state['text']}"
    response = llm.invoke(prompt)
    return {"date": response.content.strip()}

def extract_with_regex(state: State):
    match = re.search(r"\d{4}-\d{2}-\d{2}", state["text"])
    return {"date": match.group(0) if match else "UNKNOWN"}

# Graph
workflow = StateGraph(State)

workflow.add_node("llm_extract", extract_with_llm)
workflow.add_node("regex_extract", extract_with_regex)

# Normal edge
workflow.add_edge("llm_extract", END)

# Fallback edge (if LLM fails)
workflow.add_fallback("llm_extract", "regex_extract")

workflow.set_entry_point("llm_extract")
app = workflow.compile()
```

---

## üîÑ Retry Logic Example

```python
from langgraph.utils import with_retry

@with_retry(max_retries=3, delay=2)
def unreliable_node(state: State):
    # Example: API that might fail
    if random.random() < 0.5:
        raise Exception("Temporary error")
    return {"result": "Success after retry"}
```

Here:

* `max_retries=3` ‚Üí try up to 3 times.
* `delay=2` ‚Üí wait 2 seconds between retries.

---

## üìä When to Use Retries & Fallbacks

| Scenario                         | Use Retry | Use Fallback |
| -------------------------------- | --------- | ------------ |
| API timeout or connection issue  | ‚úÖ         | ‚ùå            |
| Random service instability       | ‚úÖ         | ‚ùå            |
| LLM fails to follow instructions | ‚ùå         | ‚úÖ            |
| Tool unavailable permanently     | ‚ùå         | ‚úÖ            |

---

## ‚úÖ Takeaways

* **Retries** handle *temporary failures*.
* **Fallbacks** provide *alternative solutions* when the main approach fails.
* Combining both ensures your workflow is **resilient and production-ready**.

---

üîπ **Next Step (Chapter 16)** ‚Üí We‚Äôll explore **Monitoring & Logging**: tracking performance, errors, and state transitions to debug and optimize your workflows.

---

