# Chapter 1: Getting Started

## What is LangChain?

LangChain is an open-source framework designed to simplify the development of applications powered by Large Language Models (LLMs). Instead of working directly with raw APIs, LangChain provides a structured environment to **build, orchestrate, and scale AI workflows**.

It acts as a bridge between LLMs and real-world applications by offering components for:

* **Prompt engineering** ‚Äì manage, structure, and optimize prompts.
* **RAG (Retrieval-Augmented Generation)** ‚Äì combine LLMs with external knowledge sources like databases or vector stores.
* **Agentic workflows** ‚Äì create autonomous agents that can reason, make decisions, and call tools.
* **Memory** ‚Äì maintain context across multiple user interactions.
* **Integrations** ‚Äì connect with APIs, databases, and services (e.g., OpenAI, Hugging Face, Pinecone, Chroma, SQL, etc.).

---

## Purpose and Ecosystem

The **ecosystem of LangChain** is designed around enabling developers to go from **prototype ‚Üí production-ready AI applications**:

1. **LLM Orchestration** ‚Äì unify different LLM providers (OpenAI, Anthropic, Hugging Face, Cohere, etc.) under a common API.
2. **Tooling & Agents** ‚Äì let LLMs call APIs, query data, or execute code autonomously.
3. **RAG Pipelines** ‚Äì improve accuracy by fetching domain-specific knowledge instead of relying solely on LLM memory.
4. **Workflow Management** ‚Äì chain multiple steps (prompts, decisions, retrievals) into structured pipelines.
5. **Deployment Ready** ‚Äì integrate with FastAPI, LangGraph, and cloud environments for scalability.

---

## Why Use LangChain Over Raw APIs?

While you could directly call an LLM API (like OpenAI‚Äôs `chat.completions`), LangChain offers significant advantages:

* **Abstraction** ‚Äì common interface across multiple LLM providers.
* **Reusability** ‚Äì modular components (chains, tools, memory) reduce boilerplate code.
* **Scalability** ‚Äì built-in support for workflows and production orchestration.
* **Integrations** ‚Äì plug-and-play with vector databases, APIs, and external services.
* **Community Support** ‚Äì large ecosystem of templates, examples, and community-contributed modules.

üëâ Think of LangChain as **‚ÄúTensorFlow for LLM-powered apps‚Äù** ‚Äì it gives structure, scalability, and production readiness.

---

## Installation & Setup

### Installing via pip

LangChain is available on PyPI and can be installed with:

```bash
pip install langchain
pip install langchain-openai   # OpenAI integration
pip install langchain-community  # Community integrations
```

*(Optional: install `langchain-experimental`, `langgraph`, `chromadb`, etc. based on your use case.)*

---

### Setting up API Keys

You‚Äôll need API keys for the LLM provider you plan to use. For example:

#### OpenAI

1. Create an account at [OpenAI](https://platform.openai.com/).
2. Generate an API key from your account settings.
3. Set it as an environment variable:

```bash
export OPENAI_API_KEY="your_api_key_here"    # Linux/Mac
setx OPENAI_API_KEY "your_api_key_here"      # Windows
```

#### Hugging Face

1. Create an account at [Hugging Face](https://huggingface.co/).
2. Generate a token.
3. Set it in your environment:

```bash
export HUGGINGFACEHUB_API_TOKEN="your_token_here"
```

---

## Hello World Example

Let‚Äôs run your first prompt with LangChain using OpenAI.

```python
from langchain_openai import ChatOpenAI

# Initialize LLM
llm = ChatOpenAI(model="gpt-4o-mini")  # or "gpt-3.5-turbo"

# Run your first query
response = llm.invoke("Hello LangChain! Can you explain yourself in one sentence?")

print(response.content)
```

**Expected Output (example):**

```
"LangChain is a framework that helps developers build applications powered by large language models more efficiently."
```

---

‚úÖ You‚Äôve just run your **first LangChain-powered prompt**!

From here, you can start chaining multiple steps, adding memory, or connecting external tools to make your application more powerful.

---
