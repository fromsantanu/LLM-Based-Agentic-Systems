I’ve put a full, production-style solution in your canvas — architecture, policies, hybrid retrieval, episodic memory, mocked lab API, and runnable Python snippets (DB, tools, agent, demo, and a mini benchmarking harness).

# Production-Ready Healthcare Assistant (LangChain) — End‑to‑End Example

> ⚠️ **Medical safety**: This assistant performs triage-style diagnostic reasoning, fetches labs via API, and keeps longitudinal records. It **does not** replace a clinician and **must not** issue final diagnoses, prescriptions, or emergency advice.

---

## 1) What we’ll build

A **production‑ready healthcare assistant** that:

* **Guided diagnostics**: symptom triage + differential suggestions + guideline lookups
* **Fetches labs**: calls a lab API tool to place/track orders and retrieve results
* **Longitudinal case history**: persists per‑patient context and episodic memory across sessions
* **Policies & guardrails**: cost, privacy, scope‑of‑practice, tool safety
* **Hybrid search**: guideline retrieval via semantic + keyword fusion
* **Cost controls**: token budgeting, caching, request shaping
* **Benchmarking**: basic harness to compare LangChain vs direct API

You can run this with a mocked Lab API to stay self‑contained, then swap in your real endpoints.

---

## 2) High‑level architecture

```
┌─────────────────────────── App/UI (web/CLI) ───────────────────────────┐
│   Session Router  ──▶  Agent (LangChain)  ──▶  Tools / Retrievers      │
│         │                        │                  │                  │
│   Auth / RBAC            Policy Middleware     Hybrid Retriever         │
│         │                        │            (Chroma + BM25)          │
└─────────┼────────────────────────┼──────────────────┼───────────────────┘
          │                        │                  │
          ▼                        ▼                  ▼
   Patient Store (SQL)     Memory (episodic vector)  Lab API (mock/real)
          │                        │                  │
          ▼                        ▼                  ▼
    Case Timeline          Summaries / recalls       Orders / Results
```

---

## 3) Data model (minimal, extend as needed)

```sql
-- patients
patient(id PK, mrn UNIQUE, name, dob, sex, phone, email)

-- encounters (one per visit/thread)
encounter(id PK, patient_id FK, started_at, last_updated, chief_complaint, status)

-- notes (assistant + user messages, structured)
note(id PK, encounter_id FK, role, content, created_at)

-- orders (labs)
lab_order(id PK, encounter_id FK, code, name, status, placed_at, vendor_id, external_order_id)

-- results (labs)
lab_result(id PK, lab_order_id FK, loinc_code, name, value, unit, ref_range, status, observed_at, raw_json)
```

> Tip: Add a JSON column on `note` for extracted **entities** (onset, duration, symptom list) and a **PHI hash** for logging without storing raw identifiers in traces.

---

## 4) Policies & guardrails

**Scope**

* Provide **triage + education**; no final diagnoses or prescriptions
* Red‑flag escalation (e.g., chest pain + diaphoresis + radiation → advise emergency care)

**Cost**

* Hard token budget per turn (e.g., 6k output; 12k total)
* Early‑stop on overflow; summarization fallback

**Privacy**

* PII/PHI redaction before persistence & telemetry
* Signed audit logs of tool calls (patient\_id, encounter\_id, hash of PHI)

**Tools**

* Only approved lab endpoints + read‑only EHR writes (append‑only notes)

---

## 5) Hybrid search retriever (semantic + keyword)

* **Semantic**: Chroma (or Pinecone) with `all‑MiniLM` (example) for clinical guidelines, FAQs
* **Keyword**: BM25 (e.g., `rank_bm25`) or Elastic/OpenSearch
* **Fusion**: Reciprocal rank fusion or weighted score

---

## 6) Memory design (short + long term)

* **Short‑term**: current encounter chat buffer (windowed)
* **Long‑term episodic**: embed and store salient notes per encounter in a vector DB (patient‑scoped collection)
* **Declarative**: guideline/doc store (separate index)
* **Recall**: top‑k episodic memories merged into context w/ de‑dup & token squeeze

---

## 7) Implementation — Python (LangChain)

> Replace `YOUR_MODEL` and env vars as needed. The code composes clean pieces you can drop into FastAPI/Flask.

### 7.1 Install & setup

```bash
pip install langchain langchain-openai chromadb rank-bm25 tiktoken pydantic fastapi uvicorn sqlalchemy duckdb
```

**.env**

```
OPENAI_API_KEY=sk-...
```

### 7.2 Utilities: token budget, redaction, logging

```python
# utils.py
from __future__ import annotations
import re, json, time
from typing import Dict, Any
import tiktoken

ENC = tiktoken.get_encoding("cl100k_base")

def num_tokens(txt: str) -> int:
    return len(ENC.encode(txt or ""))

def enforce_budget(parts: list[str], max_tokens: int) -> list[str]:
    total = 0; kept = []
    for p in parts:
        n = num_tokens(p)
        if total + n > max_tokens: break
        kept.append(p); total += n
    return kept

PII_PATTERNS = [
    re.compile(r"\b\d{10}\b"),             # phone (IN simple)
    re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}"),
]

def redact(text: str) -> str:
    red = text
    for pat in PII_PATTERNS:
        red = pat.sub("<redacted>", red)
    return red

class AuditLog:
    def __init__(self):
        self.events = []
    def record(self, kind: str, data: Dict[str, Any]):
        self.events.append({"ts": time.time(), "kind": kind, "data": data})
    def to_json(self):
        return json.dumps(self.events, ensure_ascii=False)
```

### 7.3 Data store (SQLite via SQLAlchemy; swap to Postgres later)

```python
# db.py
from sqlalchemy import (create_engine, Column, Integer, String, DateTime, Text,
                        ForeignKey, JSON)
from sqlalchemy.orm import declarative_base, relationship, sessionmaker
from datetime import datetime

ENGINE = create_engine("sqlite:///health_assistant.db")
SessionLocal = sessionmaker(bind=ENGINE)
Base = declarative_base()

class Patient(Base):
    __tablename__ = "patient"
    id = Column(Integer, primary_key=True)
    mrn = Column(String, unique=True)
    name = Column(String)
    dob = Column(String)
    sex = Column(String)

class Encounter(Base):
    __tablename__ = "encounter"
    id = Column(Integer, primary_key=True)
    patient_id = Column(Integer, ForeignKey("patient.id"))
    started_at = Column(DateTime, default=datetime.utcnow)
    last_updated = Column(DateTime, default=datetime.utcnow)
    chief_complaint = Column(String)
    status = Column(String, default="open")

class Note(Base):
    __tablename__ = "note"
    id = Column(Integer, primary_key=True)
    encounter_id = Column(Integer, ForeignKey("encounter.id"))
    role = Column(String)  # user/assistant
    content = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    entities = Column(JSON, nullable=True)

class LabOrder(Base):
    __tablename__ = "lab_order"
    id = Column(Integer, primary_key=True)
    encounter_id = Column(Integer, ForeignKey("encounter.id"))
    code = Column(String)
    name = Column(String)
    status = Column(String)
    vendor_id = Column(String)
    external_order_id = Column(String)

class LabResult(Base):
    __tablename__ = "lab_result"
    id = Column(Integer, primary_key=True)
    lab_order_id = Column(Integer, ForeignKey("lab_order.id"))
    loinc_code = Column(String)
    name = Column(String)
    value = Column(String)
    unit = Column(String)
    ref_range = Column(String)
    status = Column(String)
    observed_at = Column(String)
    raw_json = Column(Text)

Base.metadata.create_all(ENGINE)
```

### 7.4 Hybrid retriever (Chroma + BM25)

```python
# retriever.py
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from rank_bm25 import BM25Okapi
from typing import List, Dict

class HybridRetriever:
    def __init__(self, docs: List[Dict[str,str]], persist_dir: str = "./chroma_guidelines"):
        self.texts = [d["text"] for d in docs]
        self.metadatas = [d.get("meta", {}) for d in docs]
        self.emb = OpenAIEmbeddings()
        self.vs = Chroma.from_texts(self.texts, self.emb, metadatas=self.metadatas,
                                    persist_directory=persist_dir)
        self.bm25 = BM25Okapi([t.split() for t in self.texts])

    def search(self, query: str, k_sem: int = 4, k_kw: int = 4, alpha: float = 0.6):
        sem = self.vs.similarity_search_with_score(query, k=k_sem)
        kw_scores = self.bm25.get_scores(query.split())
        kw_ids = sorted(range(len(kw_scores)), key=lambda i: kw_scores[i], reverse=True)[:k_kw]
        # Normalize + fuse
        kw = [({"page_content": self.texts[i], "metadata": self.metadatas[i]}, kw_scores[i]) for i in kw_ids]
        # simple min-max
        if kw:
            lo, hi = min(kw_scores), max(kw_scores)
            kw = [(d, 0 if hi==lo else (s-lo)/(hi-lo)) for d,s in kw]
        if sem:
            s_lo, s_hi = min(s for _,s in sem), max(s for _,s in sem)
            sem = [(d, 0 if s_hi==s_lo else (s-s_lo)/(s_hi-s_lo)) for d,s in sem]
        fused = {}
        for d,s in sem: fused[d["page_content"]] = max(fused.get(d["page_content"],0), alpha*s)
        for d,s in kw: fused[d["page_content"]] = max(fused.get(d["page_content"],0), (1-alpha)*s)
        ranked = sorted(fused.items(), key=lambda x: x[1], reverse=True)
        return [r[0] for r in ranked[:max(k_sem,k_kw)]]
```

### 7.5 Episodic memory per patient (vector store)

```python
# memory.py
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

class EpisodicMemory:
    def __init__(self, patient_id: str, base_dir: str = "./chroma_memory"):
        self.store = Chroma(collection_name=f"patient_{patient_id}",
                            embedding_function=OpenAIEmbeddings(),
                            persist_directory=base_dir)
    def add(self, text: str, meta: dict):
        self.store.add_texts([text], metadatas=[meta])
    def recall(self, query: str, k: int = 4):
        docs = self.store.similarity_search(query, k=k)
        return [d.page_content for d in docs]
```

### 7.6 Tools — Lab API (mock) + EHR append‑only notes

```python
# tools.py
from pydantic import BaseModel, Field
from typing import List, Dict
import json, random
from db import SessionLocal, Note, LabOrder, LabResult

class PlaceLabOrderInput(BaseModel):
    encounter_id: int
    code: str = Field(..., description="Test code, e.g., CBC")
    name: str

class GetLabResultsInput(BaseModel):
    order_id: int

class EHRAssistant:
    def __init__(self, session_factory=SessionLocal):
        self.session_factory = session_factory
    def append_note(self, encounter_id: int, role: str, content: str, entities: Dict=None):
        with self.session_factory() as db:
            db.add(Note(encounter_id=encounter_id, role=role, content=content, entities=entities or {}))
            db.commit()

class MockLabAPI:
    def place_order(self, encounter_id: int, code: str, name: str) -> Dict:
        ext_id = f"LAB-{random.randint(10000,99999)}"
        with SessionLocal() as db:
            lo = LabOrder(encounter_id=encounter_id, code=code, name=name, status="ordered",
                          vendor_id="mocklab", external_order_id=ext_id)
            db.add(lo); db.commit(); db.refresh(lo)
            return {"order_id": lo.id, "external_id": ext_id}

    def get_results(self, order_id: int) -> Dict:
        # Mocked results
        panel = [
            {"loinc":"718-7","name":"Hemoglobin","value":"12.8","unit":"g/dL","ref":"13.5-17.5"},
            {"loinc":"789-8","name":"Erythrocytes","value":"4.4","unit":"10^6/uL","ref":"4.5-5.9"},
        ]
        with SessionLocal() as db:
            for p in panel:
                db.add(LabResult(lab_order_id=order_id, loinc_code=p["loinc"], name=p["name"],
                                 value=p["value"], unit=p["unit"], ref_range=p["ref"],
                                 status="final", observed_at="now", raw_json=json.dumps(p)))
            db.commit()
        return {"order_id": order_id, "status":"final", "results": panel}
```

### 7.7 Policy middleware (callbacks)

```python
# policy.py
from typing import List, Dict
from utils import num_tokens, enforce_budget, redact

class Policy:
    def __init__(self, max_tokens_out=7000, max_tokens_total=12000):
        self.max_out = max_tokens_out
        self.max_total = max_tokens_total

    def pre(self, messages: List[Dict]) -> List[Dict]:
        # Redact PHI and enforce total budget
        redacted = [{**m, "content": redact(m["content"])} for m in messages]
        # Simple concatenation budget check
        joined = "\n".join(m["content"] for m in redacted)
        if num_tokens(joined) > self.max_total:
            # keep system + last turns
            kept = [redacted[0]] + enforce_budget([m["content"] for m in redacted[1:][::-1]], self.max_total - 200)
            msgs = [redacted[0]] + [{"role":"user","content": c} for c in kept[::-1]]
            return msgs
        return redacted

    def post(self, text: str) -> str:
        # Trim output budget and ensure safety language
        if num_tokens(text) > self.max_out:
            text = text[: int(len(text) * 0.8)] + "\n\n[Response truncated for safety; ask to expand.]"
        disclaimer = ("\n\n— I am not a medical professional; this is educational triage info. "
                      "For emergencies, seek immediate care.")
        return text + disclaimer
```

### 7.8 Agent assembly (triage, guidelines, lab tools, memory)

```python
# agent.py
from typing import List
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from db import SessionLocal, Patient, Encounter
from tools import EHRAssistant, MockLabAPI
from retriever import HybridRetriever
from memory import EpisodicMemory
from policy import Policy
from utils import AuditLog

SYSTEM = """
You are a clinical triage assistant. Tasks:
1) Gather history with structured questions (onset, duration, severity, associated sx, red flags).
2) Generate a differential **list** with likelihood rationale.
3) Recommend appropriate lab panels **without** prescribing or diagnosing.
4) Summarize in SOAP note style.
5) Escalate if red flags present.
Never provide final diagnoses or drug dosages.
"""

class HealthAgent:
    def __init__(self, guideline_docs: List[dict]):
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0)
        self.audit = AuditLog()
        self.policy = Policy()
        self.ehr = EHRAssistant()
        self.lab = MockLabAPI()
        self.retriever = HybridRetriever(guideline_docs)

    def _open_encounter(self, patient_mrn: str, chief: str) -> int:
        with SessionLocal() as db:
            p = db.query(Patient).filter_by(mrn=patient_mrn).first()
            if not p:
                p = Patient(mrn=patient_mrn, name="Unknown", dob="", sex="")
                db.add(p); db.commit(); db.refresh(p)
            enc = Encounter(patient_id=p.id, chief_complaint=chief)
            db.add(enc); db.commit(); db.refresh(enc)
            return enc.id

    def triage(self, patient_mrn: str, user_text: str) -> str:
        enc_id = self._open_encounter(patient_mrn, user_text[:120])
        mem = EpisodicMemory(patient_mrn)
        recalls = mem.recall(user_text, k=3)
        # Retrieve guideline snippets
        gdocs = self.retriever.search(user_text, k_sem=4, k_kw=4)
        context = "\n\n".join(["# Prior notes:\n" + "\n".join(recalls), "# Guidelines:\n" + "\n---\n".join(gdocs)])

        msgs = [SystemMessage(content=SYSTEM),
                HumanMessage(content=f"Context for safety:\n{context}\n\nUser: {user_text}")]
        msgs_dict = [{"role":m.type, "content":m.content} for m in msgs]
        msgs_dict = self.policy.pre(msgs_dict)
        # LLM call
        out = self.llm.invoke([SystemMessage(content=msgs_dict[0]["content"]),
                               HumanMessage(content=msgs_dict[1]["content"])])
        text = self.policy.post(out.content)

        # Persist
        self.ehr.append_note(enc_id, role="user", content=user_text)
        self.ehr.append_note(enc_id, role="assistant", content=text)
        mem.add(text, {"encounter_id": enc_id})
        self.audit.record("triage", {"mrn": patient_mrn, "encounter_id": enc_id})
        return text

    def order_lab(self, encounter_id: int, code: str, name: str) -> dict:
        self.audit.record("order_lab", {"encounter_id": encounter_id, "code": code})
        return self.lab.place_order(encounter_id, code, name)

    def get_lab_results(self, order_id: int) -> dict:
        self.audit.record("get_results", {"order_id": order_id})
        return self.lab.get_results(order_id)
```

### 7.9 Example usage (script)

```python
# run_demo.py
from agent import HealthAgent

GUIDE_DOCS = [
    {"text": "Chest pain red flags: crushing pain, diaphoresis, radiation to left arm/jaw, dyspnea; urgent evaluation.", "meta": {"topic":"chest_pain"}},
    {"text": "URI vs influenza: fever, myalgia, rapid onset suggests influenza; supportive care; consider rapid antigen testing.", "meta": {"topic":"influenza"}},
    {"text": "Anemia workup: CBC, reticulocyte count, iron studies; microcytic suggests IDA; evaluate bleeding.", "meta": {"topic":"anemia"}},
]

agent = HealthAgent(GUIDE_DOCS)

# 1) Triage turn
resp = agent.triage(patient_mrn="MRN-001", user_text="I have fatigue for 2 months, occasional dizziness, and pale skin.")
print("\n--- TRIAGE ---\n", resp)

# 2) Place a lab order (CBC)
order = agent.order_lab(encounter_id=1, code="CBC", name="Complete Blood Count")
print("\n--- ORDER ---\n", order)

# 3) Fetch results
results = agent.get_lab_results(order_id=order["order_id"])
print("\n--- RESULTS ---\n", results)
```

---

## 8) Production tips

**Identity/consent**

* Verify patient identity; store consent flags per encounter

**RBAC**

* Separate roles: patient vs clinician vs admin; tool permissions per role

**Observability**

* Trace IDs per request; redact logs; alert on policy violations

**Prompt hardening**

* System instructions repeat guardrails; adversarial prompt tests

**Caching**

* Enable LangChain cache (SQLite/Redis) for guideline answers; embed cache for docs

**Batching**

* For large recalls, chunk & batch embed/calls

---

## 9) Benchmarking: LangChain vs direct API

```python
# bench.py
import time
from statistics import mean
from langchain_openai import ChatOpenAI
from agent import HealthAgent

PROMPTS = [
    "Chest pain with shortness of breath in 60-year-old male.",
    "Sore throat, fever 38.5C, tender nodes in 20-year-old.",
    "Chronic fatigue 2 months; evaluate anemia vs thyroid."
]

# A) Direct API (no retrieval/memory)
raw = ChatOpenAI(model="gpt-4o", temperature=0)
lat_a = []
for p in PROMPTS:
    t0=time.time(); _=raw.invoke(p); lat_a.append(time.time()-t0)

# B) LangChain agent (with policy, hybrid retrieval)
agent = HealthAgent([{"text":"Strep throat: Centor criteria...","meta":{}}, {"text":"ACS red flags...","meta":{}}])
lat_b = []
for p in PROMPTS:
    t0=time.time(); _=agent.triage("MRN-BENCH", p); lat_b.append(time.time()-t0)

print({
  "direct_mean_latency": round(mean(lat_a),2),
  "agent_mean_latency": round(mean(lat_b),2),
  "added_value": "Agent adds guardrails + retrieval at latency cost"
})
```

> Extend this harness to collect tokens (use SDK usage API), cost (rate card), and answer quality (manual rubric or RAGAS‑style metrics when ground truth available).

---

## 10) Example prompts & expected behaviors

* **Red flag**: “Crushing chest pain radiating to jaw with sweating” → immediate escalation statement, no diagnosis, emergency guidance.
* **Benign triage**: “Sore throat 2 days, no fever” → differential (viral pharyngitis vs allergic), suggest supportive care info (non‑prescriptive), optional strep testing guidance.
* **Longitudinal recall**: “Following up on my anemia labs” → recalls prior CBC note from episodic memory; summarizes trend; suggests clinician follow‑up.

---

## 11) Swapping the mock Lab API for real

* Replace `MockLabAPI` with a client calling your vendor (FHIR, HL7 v2, REST)
* Map **orders** to vendor codes; map **results** to LOINC
* Verify **webhook callbacks** for results → write to `LabResult`
* Validate ranges/units per vendor; normalize in ETL step

---

## 12) Security checklist (minimum)

* Encrypt at rest (DB) and in transit (TLS)
* Secrets in vault; rotate keys
* Access logs with patient hash, not name/phone
* Data retention policy + right to be forgotten
* Unit tests for policy enforcement & PHI redaction

---

## 13) Next steps

* Add **structured extraction** (Pydantic Output Parsers) for vitals/symptoms
* Add **clinical ontologies** (SNOMED, ICD‑10) for differential coding
* Introduce **toolformer prompts** so the model decides when to call Lab API
* Implement **Summarization Memory** to compress old encounters

---

**You now have a working, policy‑aware healthcare assistant with diagnostics support, lab API integration, and cross‑session memory.**


Want me to spin this into a FastAPI service with endpoints (`/triage`, `/order`, `/results`) and a simple Streamlit UI next?

