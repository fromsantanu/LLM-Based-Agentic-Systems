# Chapter 12. MCP in Practice

The **Model Context Protocol (MCP)** is not just a conceptual framework—it comes with practical SDKs and tools that enable developers to build real-world integrations between AI models, clients, and external systems. This chapter demonstrates how to set up the MCP development environment, write a basic server, and connect MCP clients to advanced backends like vector databases.

---

## Installing and Configuring MCP SDKs

The MCP ecosystem provides SDKs in multiple languages, with **Python** and **TypeScript** being the most common. These SDKs simplify the process of creating servers, clients, and context providers.

### Installation (Python example)

```bash
pip install mcp-sdk
```

### Configuration

* Ensure you have **Python 3.9+** installed.
* Install MCP SDK globally or within a virtual environment.
* Configure your development environment with the MCP CLI for debugging and quick server launches:

```bash
pip install mcp-cli
```

You can verify installation with:

```bash
mcp --help
```

---

## Example: Writing a Simple MCP Server in Python

The following example shows how to implement a basic **MCP server** that exposes a simple resource (a list of quotes).

### server.py

```python
from mcp.server import Server
from mcp.types import Resource

# Create an MCP server instance
server = Server("QuotesServer")

# Define a resource (context provider)
@server.resource("quotes")
def provide_quotes():
    return [
        Resource(
            uri="quotes://1",
            name="Motivational Quote",
            value="Stay curious, stay kind, keep learning."
        ),
        Resource(
            uri="quotes://2",
            name="Humor Quote",
            value="Why don’t scientists trust atoms? Because they make up everything!"
        ),
    ]

if __name__ == "__main__":
    server.run()
```

### Run the server

```bash
python server.py
```

The server now exposes quotes as retrievable resources for MCP clients.

---

## Example: Connecting an MCP Client to a Vector Database

One of the most powerful use cases of MCP is **retrieval-augmented generation (RAG)** workflows. By connecting an MCP client to a **vector database** like **Qdrant**, **Pinecone**, or **ChromaDB**, AI models can retrieve semantically relevant information to enrich responses.

### Client Setup

Install a vector database client library (example with Qdrant):

```bash
pip install qdrant-client
```

### mcp\_client.py

```python
from mcp.client import Client
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams

# Connect MCP client
client = Client("VectorClient")

# Connect to local Qdrant instance
qdrant = QdrantClient("http://localhost:6333")

# Ensure a collection exists
collection_name = "docs"
qdrant.recreate_collection(
    collection_name=collection_name,
    vectors_config=VectorParams(size=384, distance="Cosine")
)

# Insert a document vector
qdrant.upsert(
    collection_name=collection_name,
    points=[
        PointStruct(id=1, vector=[0.1] * 384, payload={"text": "MCP connects AI to context."})
    ]
)

# Define MCP tool to query vectors
@client.tool("search_docs")
def search_docs(query_vector: list[float]):
    results = qdrant.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=3
    )
    return [hit.payload for hit in results]

if __name__ == "__main__":
    client.run()
```

Now, any MCP-compatible AI model can invoke the `search_docs` tool to fetch relevant context from the vector database during inference.

---

## Key Takeaways

* MCP SDKs streamline the process of building servers and clients.
* A **server** provides resources (structured data, APIs, tools) to clients.
* A **client** can connect to advanced systems like **vector databases** to power RAG workflows.
* MCP ensures **interoperability**, letting developers focus on their domain logic rather than reinventing communication protocols.

---

