# **Chapter 14 - Deploying Agentic Workflows**

Once you’ve built and tested your agentic workflows locally in **N8N**, the next step is to deploy them into production. A reliable deployment ensures that workflows can scale, remain fault-tolerant, and provide observability into agent behavior. This chapter covers hosting options, scaling strategies, and monitoring best practices.

---

## 1. Running N8N on VPS / Hostinger / Docker

You can deploy N8N in several environments depending on your needs:

### a) VPS (Virtual Private Server)

* **Providers:** DigitalOcean, Linode, Hostinger, AWS Lightsail.
* **Steps:**

  1. Provision a server (Ubuntu/Debian preferred).
  2. Install **Node.js**, **npm/yarn**, and **n8n**.
  3. Use **PM2** or **systemd** to run N8N as a background service.
  4. Configure reverse proxy with **NGINX** and SSL (via Let’s Encrypt).

✅ Pros: Cost-effective, flexible, customizable.
⚠️ Cons: Requires manual setup and updates.

---

### b) Hostinger

* Hostinger offers **managed VPS** and **Docker support**, making it easy to run N8N with minimal DevOps effort.
* You can:

  * Deploy via **Docker Compose** in Hostinger VPS.
  * Use Hostinger’s **hPanel** to manage domains, SSL, and networking.
  * Benefit from automated backups.

✅ Pros: Easier setup, cheaper than cloud giants.
⚠️ Cons: Less fine-grained scaling than AWS/GCP/Azure.

---

### c) Docker & Docker Compose

* **Recommended** method for portability and reproducibility.
* Example `docker-compose.yml`:

```yaml
version: "3.8"
services:
  n8n:
    image: n8nio/n8n
    restart: always
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=securepassword
    volumes:
      - n8n_data:/home/node/.n8n

volumes:
  n8n_data:
```

Run:

```bash
docker-compose up -d
```

✅ Pros: Fast deployment, easy upgrades, portable.
⚠️ Cons: Must manage Docker infrastructure.

---

## 2. Scaling Workflows with Queues

As workflows grow in complexity and traffic, **scaling** becomes essential.

### a) Worker Mode

* N8N supports **worker mode** with **Redis queues**.
* The main process (queue manager) pushes tasks into Redis.
* Multiple workers consume tasks in parallel.

```bash
n8n start --queue
n8n worker
```

### b) Horizontal Scaling

* Run multiple **worker containers** across servers.
* Use **Kubernetes** or **Docker Swarm** for orchestration.
* Great for **high-throughput workflows** (e.g., email processing, AI agents handling queries).

### c) Scaling Strategies

* **Batch processing:** Schedule workers for heavy nightly jobs.
* **Dedicated workers:** Assign certain workers to AI-heavy flows (like LLM calls).
* **Priority queues:** Route urgent workflows (e.g., healthcare triage) separately.

---

## 3. Monitoring and Logging Agent Behavior

Agentic workflows can behave unexpectedly. Observability is crucial.

### a) Built-in N8N Logging

* Logs stored in local files or containers.
* View via `docker logs n8n` or system logs.

### b) Centralized Logging

* Connect to **ELK Stack** (Elasticsearch, Logstash, Kibana) or **Grafana Loki**.
* Helps visualize errors, execution time, and agent actions.

### c) Metrics and Monitoring

* Use **Prometheus exporters** for workflow metrics.
* Visualize workflow success rates, queue latency, and resource usage in **Grafana dashboards**.

### d) Error Notifications

* Configure N8N to send alerts via **Slack, Email, or Telegram** when workflows fail.
* Example: A healthcare bot triggers alerts if diagnosis API fails.

---

## ✅ Key Takeaways

* **VPS, Hostinger, and Docker** are the main deployment options.
* **Worker + Redis queue** architecture enables scalable, fault-tolerant workflows.
* **Centralized logging + monitoring** ensures reliability and transparency of agent behavior.

---

