# **Chapter 4 - Designing an AI Workflow in N8N**

When building **Agentic AI workflows in N8N**, the central goal is to reliably process input, run it through an **LLM (Large Language Model)**, and return structured, usable output. Since LLMs are probabilistic, ensuring consistency and robustness requires proper design choices.

---

## 1. Workflow Structure: Input → LLM → Output

The most common AI workflow in N8N can be visualized as:

```
Trigger/Input Node → Preprocessing → LLM Node → Postprocessing → Output Node
```

* **Trigger/Input Node**
  Defines how data enters the workflow (Webhook, Manual Trigger, Email, or API request).

* **Preprocessing**
  Clean, validate, or enrich incoming data. Example: normalizing text, extracting metadata, or adding system instructions.

* **LLM Node**
  Sends the prepared input to a language model (OpenAI, HuggingFace, or local model via API).
  Example: "Summarize this article into 3 key points."

* **Postprocessing**
  Parse the LLM output, transform into a structured format (JSON, CSV, or database entry), or apply logic based on results.

* **Output Node**
  Final destination for results (Google Sheets, Slack, Email, API response, Database, etc.).

---

## 2. Using JSON Formatting for Reliable Responses

LLMs often produce verbose natural language, which is difficult to parse. To ensure machine-readable output, enforce **JSON schema** formatting in your prompts.

### Prompt Example

```text
You are an assistant that extracts patient details from text.
Return output only in valid JSON:
{
  "name": string,
  "age": number,
  "symptoms": [string],
  "diagnosis": string
}
```

### Benefits:

* **Predictable Structure** → Easy to parse in N8N.
* **Validation** → Use N8N’s `IF` or `Function` nodes to check JSON validity.
* **Integration** → JSON flows smoothly into databases, APIs, or downstream services.

### Common N8N Nodes:

* **Function Node** → `JSON.parse()` validation.
* **IF Node** → Route based on missing/invalid fields.
* **Code Node** → Auto-fix minor JSON errors (missing commas, unquoted keys).

---

## 3. Error Handling and Retries

Since LLMs and APIs can fail (timeouts, rate limits, malformed JSON), robust error handling is critical.

### Techniques in N8N:

1. **Error Workflow**

   * Every N8N workflow can define an **Error Workflow** that is triggered on failure.
   * Use this to log errors, notify via Slack/Email, or retry.

2. **Retry Logic**

   * Wrap LLM calls with the **Error Trigger + Wait + Re-execute** pattern.
   * Example: Retry 3 times with exponential backoff (`5s → 15s → 45s`).

3. **Validation Loops**

   * After parsing JSON, check schema completeness.
   * If invalid, send corrective instruction back to the LLM:
     *"The previous response was invalid. Please reformat into valid JSON with keys X, Y, Z."*

4. **Timeout & Rate Limits**

   * Use N8N’s **HTTP Request Node** timeout settings.
   * Add a **Queue or Wait Node** to control request frequency and avoid API rate limit errors.

---

## Example Workflow

**Use case: Summarize customer feedback from an API and send structured results to a database.**

1. **Trigger Node** → Webhook receives new feedback text.
2. **Preprocess Node** → Clean text.
3. **LLM Node** → Summarize feedback, output in JSON (`{"summary": "...", "sentiment": "...", "tags": [...]}`).
4. **Validation Node** → Function checks JSON validity.
5. **Error Handling** → If invalid, send prompt correction loop.
6. **Database Node** → Insert structured summary into Postgres.
7. **Notification Node** → Send Slack message with summary + sentiment.

---

✅ **Key Takeaways**:

* Always structure N8N AI workflows as **Input → LLM → Output** with clear preprocessing and postprocessing steps.
* Use **JSON formatting** in prompts to enforce structured responses.
* Add **error handling and retry logic** for robustness against API or model failures.

---

