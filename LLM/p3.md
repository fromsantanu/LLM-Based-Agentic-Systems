# 3. Core Capabilities

Large Language Models (LLMs) demonstrate a wide range of capabilities derived from their training on massive text corpora. These capabilities are not hard-coded but emerge from the model’s ability to learn statistical patterns of language, context, and reasoning. This chapter explores the most important core capabilities that form the foundation of practical applications.

---

## 3.1 Text Generation (Next-Word Prediction)

At their core, LLMs are **probabilistic next-word predictors**. Given a sequence of words (tokens), the model estimates the probability distribution of the next token. By sampling from this distribution, the model can generate coherent text that follows linguistic and contextual patterns.

* **Greedy decoding**: choosing the most probable next token each time.
* **Beam search**: exploring multiple candidate sequences for more fluent results.
* **Sampling & temperature**: controlling creativity by adding randomness.

**Applications**: Creative writing, dialogue systems, storytelling, automated reports, chatbots.

---

## 3.2 Summarization and Paraphrasing

LLMs excel at condensing information while retaining meaning.

* **Extractive summarization**: selecting the most important sentences.
* **Abstractive summarization**: generating new phrasing to express the same ideas.

They can also paraphrase text by rephrasing while preserving meaning, tone, or level of complexity.

**Applications**:

* Summarizing research papers or news articles.
* Creating executive summaries.
* Rewriting text for different audiences (e.g., simpler for students, technical for experts).

---

## 3.3 Question Answering

LLMs can retrieve and compose answers to natural-language questions by leveraging contextual understanding. There are two main paradigms:

* **Closed-book QA**: the model answers based on internal knowledge from pretraining.
* **Open-book QA**: combined with external sources (e.g., search engines, vector databases) for accuracy and freshness.

**Applications**:

* Chat-based Q\&A assistants.
* Customer support bots.
* Academic tutoring systems.

---

## 3.4 Reasoning and Chain-of-Thought Prompting

Beyond surface-level answers, LLMs can perform step-by-step reasoning when guided by **chain-of-thought prompting**.

* **Simple reasoning**: arithmetic, logical deductions, causal reasoning.
* **Complex reasoning**: multi-step explanations, planning, hypothesis testing.

While reasoning remains imperfect, explicit prompting (e.g., “Let’s think step by step”) significantly improves performance.

**Applications**:

* Math problem solving.
* Legal and policy analysis.
* Scientific research assistance.

---

## 3.5 Code Generation and Debugging

Trained on vast amounts of programming data, LLMs can generate and explain code across languages such as Python, R, Java, and JavaScript. Capabilities include:

* **Code completion**: suggesting the next line or block.
* **Code translation**: converting between languages.
* **Debugging**: identifying and fixing errors in code snippets.
* **Documentation**: generating explanations and inline comments.

**Applications**:

* AI pair programmers (e.g., GitHub Copilot).
* Accelerating software prototyping.
* Teaching programming concepts.

---

## 3.6 Multi-Lingual Capabilities and Translation

LLMs trained on multilingual corpora can understand and generate text across many languages, even in **zero-shot scenarios** (languages not explicitly included in fine-tuning).

* **Direct translation**: sentence or document translation.
* **Cross-lingual reasoning**: answering questions in one language using knowledge from another.
* **Multilingual generation**: switching between languages in a single output.

**Applications**:

* Real-time translation tools.
* Global collaboration platforms.
* Multilingual search and knowledge retrieval.

---

## Summary

The **core capabilities of LLMs**—text generation, summarization, question answering, reasoning, code generation, and multilingual support—make them powerful general-purpose tools. Each capability unlocks a wide range of real-world applications, from productivity tools to scientific discovery. These foundational abilities serve as building blocks for more advanced and domain-specific applications, which will be explored in later chapters.

---
