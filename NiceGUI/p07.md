# **Lesson 7: Connecting NiceGUI Chat to a FastAPI Backend**

In this lesson, you will:

* create a **FastAPI backend** that receives a message and sends back a reply
* connect your **NiceGUI chat UI** to that backend
* see the full flow:
  **Type ‚Üí Send ‚Üí Backend ‚Üí Reply ‚Üí Show in chat**

---

## üîç Real-life picture

Imagine a clinic:

* The **reception desk** talks to patients.
* The **doctor in a room** does the real thinking and gives advice.

Here:

* NiceGUI chat = **reception desk (front-end)**
* FastAPI = **doctor (back-end)**

NiceGUI will send the message to FastAPI.
FastAPI will prepare a reply and send it back.

---

# ‚úÖ What we will build

We‚Äôll make **two small Python programs**:

1. `backend_chat.py` ‚Üí FastAPI app
2. `chat_frontend.py` ‚Üí NiceGUI app

---

# üß© Step 1: Install required packages

In your terminal:

```bash
pip install fastapi "uvicorn[standard]" nicegui requests
```

* `fastapi` ‚Üí backend web service
* `uvicorn` ‚Üí runs the FastAPI app
* `nicegui` ‚Üí frontend UI
* `requests` ‚Üí lets NiceGUI call the backend from Python

---

# üß© Step 2: Create the FastAPI backend

Create a file: **`backend_chat.py`**

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    reply: str

@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(request: ChatRequest):
    user_message = request.message

    # here you can later call AI or any logic
    reply_text = f"I (FastAPI) received: '{user_message}'"

    return ChatResponse(reply=reply_text)
```

---

## üßæ Explanation (backend)

### `from fastapi import FastAPI`

We bring in FastAPI to create a small web app.

### `from pydantic import BaseModel`

We use this to define simple data shapes (like forms).

---

### `app = FastAPI()`

This creates the main FastAPI application.

Think of it as the ‚Äúdoctor‚Äôs room‚Äù that can receive messages.

---

### `class ChatRequest(BaseModel):`

This defines what we **expect to receive**:

```python
message: str
```

So our backend expects JSON like:

```json
{"message": "Hello"}
```

---

### `class ChatResponse(BaseModel):`

This defines what we **send back**:

```python
reply: str
```

So we will respond with:

```json
{"reply": "some text here"}
```

---

### `@app.post("/chat", response_model=ChatResponse)`

This says:

* We listen on the path `/chat`
* We want a **POST** request
* We will send back a `ChatResponse`

---

### `def chat_endpoint(request: ChatRequest):`

This function runs when someone sends a POST request to `/chat`
with JSON like `{"message": "hello"}`.

---

### `user_message = request.message`

Get the user‚Äôs text.

---

### `reply_text = f"I (FastAPI) received: '{user_message}'"`

Make a simple reply.
Later, this can be replaced with AI, database, or your own logic.

---

### `return ChatResponse(reply=reply_text)`

Send back a JSON response with the reply text.

---

## ‚ñ∂Ô∏è Run the backend

In the terminal:

```bash
uvicorn backend_chat:app --reload
```

* `backend_chat` ‚Üí file name (without `.py`)
* `app` ‚Üí the FastAPI object inside that file

You should see something like:

> Uvicorn running on [http://127.0.0.1:8000](http://127.0.0.1:8000)

Our backend URL will be:
`http://localhost:8000/chat`

---

# üß© Step 3: Create the NiceGUI chat frontend

Now create another file: **`chat_frontend.py`**

```python
from nicegui import ui
import requests

BACKEND_URL = "http://localhost:8000/chat"

messages = []

def send_message():
    user_text = input_box.value

    if not user_text.strip():
        return

    # add user's message to chat
    messages.append(f"You: {user_text}")

    try:
        # send message to FastAPI backend
        response = requests.post(
            BACKEND_URL,
            json={"message": user_text},
            timeout=10
        )
        response.raise_for_status()
        data = response.json()
        bot_reply = data.get("reply", "No reply from backend.")
    except Exception as e:
        bot_reply = f"Error talking to backend: {e}"

    # add backend reply to chat
    messages.append(f"Bot: {bot_reply}")

    # refresh chat area
    chat_area.clear()
    for msg in messages:
        ui.label(msg, parent=chat_area)

    # clear input
    input_box.value = ""

with ui.column().classes('w-1/2 q-pa-md'):
    ui.label('NiceGUI Chat (Connected to FastAPI)').classes('text-h5')

    chat_area = ui.column().classes(
        'border rounded p-4 h-64 overflow-y-auto bg-white'
    )

    with ui.row().classes('w-full items-center q-pt-md'):
        input_box = ui.input(
            placeholder='Type your message here...'
        ).classes('w-full')
        ui.button('Send', on_click=send_message)

ui.run()
```

---

## üßæ Explanation (frontend)

### `from nicegui import ui`

We use NiceGUI to build the page.

### `import requests`

We use `requests` to call the FastAPI backend.

---

### `BACKEND_URL = "http://localhost:8000/chat"`

This is where our FastAPI backend is running.
If you change FastAPI port later, update this URL.

---

### `messages = []`

A list to store chat history.

---

### `def send_message():`

This function runs when the **Send** button is clicked.

---

### `user_text = input_box.value`

Read what the user typed.

---

### `if not user_text.strip():`

If empty or only spaces, do nothing.

---

### `messages.append(f"You: {user_text}")`

Add the user‚Äôs message to the chat history.

---

### The backend call:

```python
response = requests.post(
    BACKEND_URL,
    json={"message": user_text},
    timeout=10
)
```

* `requests.post` ‚Üí send a POST request
* `BACKEND_URL` ‚Üí where to send
* `json={"message": user_text}` ‚Üí the data we send to FastAPI
* `timeout=10` ‚Üí wait up to 10 seconds

---

### `response.raise_for_status()`

If the server returned an error (e.g. 404 or 500), this will raise an exception.

---

### `data = response.json()`

We read the JSON body returned by FastAPI.
It should look like: `{"reply": "I (FastAPI) received: 'Hello'"}`

---

### `bot_reply = data.get("reply", "No reply from backend.")`

Get the text from the `"reply"` field.

If it doesn‚Äôt exist, use `"No reply from backend."`.

---

### `except Exception as e:`

If anything goes wrong (backend not running, wrong URL, etc.),
we prepare an error message.

---

### `messages.append(f"Bot: {bot_reply}")`

Add the bot‚Äôs reply to chat history.

---

### Refreshing the chat area:

```python
chat_area.clear()
for msg in messages:
    ui.label(msg, parent=chat_area)
```

We clear all old labels and re-draw them from the `messages` list.

---

### `input_box.value = ""`

Clear the input after sending.

---

### Layout section

```python
with ui.column().classes('w-1/2 q-pa-md'):
    ui.label('NiceGUI Chat (Connected to FastAPI)').classes('text-h5')
```

We create a vertical layout and add a title.

---

```python
chat_area = ui.column().classes(
    'border rounded p-4 h-64 overflow-y-auto bg-white'
)
```

This is the scrollable chat area, like in Lesson 6.

---

```python
with ui.row().classes('w-full items-center q-pt-md'):
    input_box = ui.input(...).classes('w-full')
    ui.button('Send', on_click=send_message)
```

We put the input box and Send button in one row.

---

### `ui.run()`

Starts the NiceGUI app on `http://localhost:8080`

---

# ‚ñ∂Ô∏è Step 4: Run everything

1. **Start FastAPI backend**
   In terminal 1:

   ```bash
   uvicorn backend_chat:app --reload
   ```

2. **Start NiceGUI frontend**
   In terminal 2:

   ```bash
   python chat_frontend.py
   ```

3. Open your browser and go to:

   ```
   http://localhost:8080
   ```

4. Type a message and press **Send**.

You should see:

* ‚ÄúYou: your message‚Äù
* ‚ÄúBot: I (FastAPI) received: 'your message'‚Äù

And in the terminal where FastAPI runs, you‚Äôll see log lines for each request.

---

# üí° Tips & Best Practices

### ‚úÖ Tip 1: Check backend first

If the chat shows an error like
‚ÄúError talking to backend‚Ä¶‚Äù,
open your browser and try:

`http://localhost:8000/docs`

If that page doesn‚Äôt open, your FastAPI app is not running.

---

### ‚úÖ Tip 2: This is where AI will plug in

Inside `chat_endpoint` in `backend_chat.py`,
you can later add your **OpenAI / diagnostic / logic** code.

For example, replace:

```python
reply_text = f"I (FastAPI) received: '{user_message}'"
```

with a call to your AI function.

---

