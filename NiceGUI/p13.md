# **Lesson 13: Using WebSockets for Live Chat Updates**

In the earlier lessons, every time you pressed **Send**, the message went to the backend using a **normal HTTP request**.

This worksâ€¦
but it is not truly *live*.

To make the chat feel smoother (like WhatsApp or Messenger), we need a way for the browser and the server to stay **connected all the time**, so they can send messages instantly.

This is where **WebSockets** come in.

---

## ğŸ§  Real-life example

Think of a phone call vs SMS.

* **SMS** â†’ send â†’ wait â†’ receive reply
* **Phone call** â†’ both sides stay connected â†’ talk instantly

Normal HTTP is like SMS.
WebSockets are like a phone call â€” both sides stay connected.

In this lesson, we will make our NiceGUI chat behave like a **phone call** connection with the backend.

---

# â­ What we will build

We will build:

* a NiceGUI page that connects to the backend through WebSockets
* messages appear instantly (no refresh, no delay)
* the backend sends replies in real-time
* the chat updates the moment a new message arrives

This looks much smoother and modern.

---

# â­ PART A â€” WebSocket-enabled NiceGUI frontend

NiceGUI makes WebSockets very easy because NiceGUI itself uses WebSockets internally.

We just need to:

1. Create a **live message stream**
2. Update chat UI the moment new messages arrive
3. Send messages to backend using `ui.socket()`

---

## ğŸ’» Code: NiceGUI with WebSockets

Save as: **chat_ui_websocket.py**

```python
from nicegui import ui
import asyncio
import json
import websockets  # install using: pip install websockets

SERVER_WS_URL = "ws://localhost:8000/ws"

ui.session_state.setdefault("chat_history", [])

async def send_message():
    user_text = input_box.value
    if not user_text.strip():
        return

    input_box.value = ""

    # add doctor message locally
    ui.session_state.chat_history.append({"role": "doctor", "content": user_text})
    refresh_chat()

    # send message to backend WebSocket
    await ws.send(json.dumps({
        "role": "doctor",
        "content": user_text
    }))

async def read_messages():
    """Constantly listen to backend WebSocket for live updates."""
    async for message in ws:
        data = json.loads(message)
        ui.session_state.chat_history.append({
            "role": "assistant",
            "content": data.get("reply", "")
        })
        refresh_chat()

def refresh_chat():
    chat_area.clear()
    for msg in ui.session_state.chat_history:
        label = ui.label(f"{msg['role'].capitalize()}: {msg['content']}", parent=chat_area)
        label.classes("p-2 rounded bg-blue-50" if msg['role']=="doctor" else "p-2 rounded bg-green-50")

with ui.column().classes("w-1/2 q-pa-md"):
    ui.label("Medical Diagnostic Chat (WebSocket)").classes("text-h5")

    chat_area = ui.column().classes("border rounded p-4 h-64 overflow-y-auto bg-white")

    with ui.row():
        input_box = ui.input(placeholder="Describe symptoms...").classes("w-full")
        ui.button("Send", on_click=send_message)

# connect to WebSocket server
async def main():
    global ws
    ws = await websockets.connect(SERVER_WS_URL)
    ui.timer(0.1, lambda: None)  # refresh UI
    asyncio.create_task(read_messages())

asyncio.get_event_loop().create_task(main())

ui.run()
```

---

# ğŸ§¾ Explanation (frontend)

### âœ” WebSocket connection

```python
ws = await websockets.connect(SERVER_WS_URL)
```

This keeps a *live* connection open.

---

### âœ” Sending messages

```python
await ws.send(json.dumps({...}))
```

Messages go instantly to FastAPI.

---

### âœ” Reading messages

```python
async for message in ws:
    ...
```

This means:

* keep listening forever
* update chat as soon as backend replies

---

### âœ” No â€œSend â†’ Wait â†’ Refreshâ€

Messages appear instantly using WebSockets.

---

---

# â­ PART B â€” FastAPI WebSocket backend

Now we create a backend that uses WebSocket instead of normal POST requests.

---

## ğŸ’» Code: Backend with WebSockets

Save as: **backend_ws.py**

```python
import os
import json
from fastapi import FastAPI, WebSocket
from openai import OpenAI

app = FastAPI()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()

    while True:
        raw = await websocket.receive_text()
        message = json.loads(raw)

        doctor_message = message["content"]

        # AI reasoning logic
        system_prompt = (
            "You are an AI medical assistant who helps a doctor by doing differential "
            "diagnosis and asking structured follow-up questions."
        )

        reply = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": doctor_message},
            ],
        )

        ai_text = reply.choices[0].message["content"]

        # send reply back over WebSocket
        await websocket.send_text(json.dumps({"reply": ai_text}))
```

---

# ğŸ§¾ Explanation (backend)

### âœ” `@app.websocket("/ws")`

This opens a WebSocket route at:

```
ws://localhost:8000/ws
```

---

### âœ” accept the connection

```python
await websocket.accept()
```

Now the backend is ready to talk.

---

### âœ” receive doctorâ€™s message instantly

```python
raw = await websocket.receive_text()
```

This happens the moment NiceGUI sends something.

---

### âœ” send response instantly

```python
await websocket.send_text(json.dumps({"reply": ai_text}))
```

The message reaches NiceGUI **without waiting for a refresh**.

---

---

# â–¶ï¸ Running the system

### Step 1: Start the WebSocket backend

```bash
uvicorn backend_ws:app --reload
```

### Step 2: Start the WebSocket NiceGUI UI

```bash
python chat_ui_websocket.py
```

### Step 3: Open browser

```
http://localhost:8080
```

### Type:

> Patient has fever and dry cough.

AI instantly replies, without waiting for HTTP delays.

This feels very smooth.

---

# ğŸ’¡ Tips & Best Practices

### âœ” Tip 1 â€” Use WebSockets for â€œliveâ€ medical consultation

No waiting time.
Immediate feedback.
Supports multi-user live rooms.

---

### âœ” Tip 2 â€” Send structured data

Instead of plain text, you can send:

```json
{
  "doctor_id": 101,
  "patient_id": 202,
  "symptoms": "fever, cough"
}
```

---

### âœ” Tip 3 â€” Support multi-user chat rooms

Using:

* WebSocket â€œroomsâ€
* Broadcasting replies
* Group messages per patient

We can add this in the next lesson.

---

### âœ” Tip 4 â€” Add a â€œprocessingâ€¦â€ animation

Already partially done using NiceGUI; we can expand it later.

---

# ğŸ‰ Summary

In this lesson, you learned how to:

* build a live chat UI using NiceGUI
* maintain a WebSocket connection
* receive instant replies without refreshing
* add AI-powered clinical logic
* improve user experience tremendously

Your chatbot is now **real-time**, which is ideal for doctors using your diagnostic assistant.

---
