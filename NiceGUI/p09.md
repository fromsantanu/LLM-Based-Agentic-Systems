# **Lesson 9: Maintaining Conversation Context (Session-Based Storage)**

In this lesson, you will learn how to make your chatbot **remember the conversation** instead of treating each message as brand new.

Right now, your chatbot talks like this:

* You: â€œHiâ€
* Bot: â€œI received â€˜Hiâ€™.â€
* You: â€œWhat is my name?â€
* Bot: â€œI received â€˜What is my name?â€™.â€

The bot doesnâ€™t remember anything you said before.

We want to change this so the chatbot behaves more naturally.

---

## ğŸ§  Real-life example

Think of talking to a shopkeeper.

If you say:

> â€œGive me 1 kg rice.â€

and then after some time:

> â€œAdd 2 packets of salt.â€

The shopkeeper remembers your first order.

Our chatbot must also remember earlier messages in the same session.

This is called **session-based context**.

---

# â­ What we will do

We will:

1. Store the conversation inside a **session dictionary**
2. Send the **entire history** to the backend
3. Let the backend pass this history to **OpenAI or LangChain**
4. Get meaningful replies that match the conversation flow

---

# â­ PART A â€” Storing chat history in NiceGUI (frontend)

We will modify your existing NiceGUI code.

### Main change:

Instead of keeping just a list called `messages`,
we will store all messages inside the **user session**.

Session = temporary memory for each user while they are using the chatbot.

---

## ğŸ’» Updated NiceGUI Code (frontend)

Create file: **chat_frontend_context.py**

```python
from nicegui import ui
import requests

BACKEND_URL = "http://localhost:8000/chat"

# store conversation in session_state (per user)
ui.session_state.setdefault("chat_history", [])

def send_message():
    user_text = input_box.value

    if not user_text.strip():
        return

    # add user's message to the session-based memory
    ui.session_state.chat_history.append(
        {"role": "user", "content": user_text}
    )

    # send full history to backend
    try:
        response = requests.post(
            BACKEND_URL,
            json={"history": ui.session_state.chat_history},
            timeout=10
        )
        response.raise_for_status()
        data = response.json()
        bot_reply = data.get("reply", "No reply from backend.")
    except Exception as e:
        bot_reply = f"Error talking to backend: {e}"

    # add bot message to history
    ui.session_state.chat_history.append(
        {"role": "assistant", "content": bot_reply}
    )

    # refresh chat UI
    chat_area.clear()
    for msg in ui.session_state.chat_history:
        text = f"{msg['role'].capitalize()}: {msg['content']}"
        ui.label(text, parent=chat_area)

    input_box.value = ""

with ui.column().classes('w-1/2 q-pa-md'):
    ui.label('Chat with Context Memory').classes('text-h5')

    chat_area = ui.column().classes(
        'border rounded p-4 h-64 overflow-y-auto bg-white'
    )

    with ui.row().classes('w-full items-center q-pt-md'):
        input_box = ui.input(
            placeholder='Type your message here...'
        ).classes('w-full')
        ui.button('Send', on_click=send_message)

ui.run()
```

---

## ğŸ§¾ Explanation (frontend)

### `ui.session_state.setdefault("chat_history", [])`

This creates a **private memory box** for each user of the chat.

Each user gets their own `chat_history`.

---

### `ui.session_state.chat_history.append({"role": "user", "content": user_text})`

We save each user message in the session.

---

### Sending history to backend:

```python
json={"history": ui.session_state.chat_history}
```

So now the backend receives a **list of all messages**, not just one.

---

### The bot reply is also added:

```python
ui.session_state.chat_history.append({"role": "assistant", "content": bot_reply})
```

Now both sides of the conversation are stored.

---

### `chat_area.clear()` + loop

This redraws everything, so the conversation appears nicely one below another.

---

# â­ PART B â€” Updating FastAPI to use conversation history

Now the backend must handle **the full list of messages**.

---

## ğŸ’» Updated FastAPI Backend

Create file: **backend_chat_context.py**

```python
import os
from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI

app = FastAPI()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    history: list[ChatMessage]

class ChatResponse(BaseModel):
    reply: str

@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(request: ChatRequest):

    # convert history into OpenAI format
    messages = [
        {"role": msg.role, "content": msg.content}
        for msg in request.history
    ]

    # call the AI with entire history
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    reply_text = completion.choices[0].message["content"]

    return ChatResponse(reply=reply_text)
```

---

## ğŸ§¾ Explanation (backend)

### `history: list[ChatMessage]`

Backend receives **all past messages** each time somebody chats.

---

### Rebuild message list:

```python
messages = [
    {"role": msg.role, "content": msg.content}
    for msg in request.history
]
```

This makes the history ready for OpenAI format.

---

### OpenAI call:

```python
completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages
)
```

Now the model receives **the entire conversation**, not just the last message.

This is how AI maintains context.

---

# â–¶ï¸ Running both

1. Start backend:

```bash
uvicorn backend_chat_context:app --reload
```

2. Start frontend:

```bash
python chat_frontend_context.py
```

3. Open browser:

```
http://localhost:8080
```

Try talking:

> You: My name is Rohan
> Bot: Hello Rohan!
> You: What is my name again?
> Bot: Your name is Rohan.

This happens because the model saw **all previous conversation lines**.

---

# ğŸ Bonus: Try clearing the session

You may add a button:

```python
ui.button('Reset Chat', on_click=lambda: ui.session_state.update(chat_history=[]))
```

Useful when testing long sessions.

---

# ğŸ’¡ Tips & Best Practices

### âœ” Tip 1 â€” Keep the history small

Too long history can slow down the model.
After 30â€“40 messages, you may trim the older ones.

---

### âœ” Tip 2 â€” Always keep messages clean

Use only:

* `role = "user"`
* `role = "assistant"`

These are understood well by OpenAI.

---

### âœ” Tip 3 â€” You can add memory rules

For example: keep user's name always at top as a system message.

---

# ğŸ‰ Summary

In this lesson you learned:

* how to store messages inside NiceGUI session
* how to send full conversation to FastAPI
* how to make OpenAI respond using all previous context
* how to make chatbot replies more intelligent and personal

Your chatbot is now **context-aware**, meaning it can carry meaningful conversations.

---

