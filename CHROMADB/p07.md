# **Chapter 7. Persistence & Deployment**

When moving from experiments to production use, persistence and deployment become crucial. ChromaDB offers multiple options for storing data persistently, deploying within containerized environments like Docker, and handling large datasets. This chapter walks through these aspects in detail.

---

## Persistent Storage (SQLite Backend)

By default, Chroma runs in **in-memory mode**, which means your data is lost when the process stops. To persist collections across sessions, you can use the **SQLite backend**.

```python
import chromadb

# Use persistent storage
client = chromadb.PersistentClient(path="chroma_store")

# Create or get a collection
collection = client.get_or_create_collection(name="my_docs")

# Add documents
collection.add(
    documents=["Machine learning is powerful.", "Chroma stores embeddings."],
    ids=["doc1", "doc2"]
)
```

* `path="chroma_store"` creates a folder where Chroma stores the SQLite database and associated files.
* The next time you start the client with the same path, the collections and embeddings will be available.

---

## Using Chroma with Docker

For production, containerization ensures portability and reproducibility. Chroma provides a Docker image you can run directly.

### Running Chroma with Docker

```bash
docker run -d \
  -p 8000:8000 \
  -v $(pwd)/chroma_data:/chroma/chroma \
  chromadb/chroma
```

* `-p 8000:8000` exposes Chroma’s HTTP API on port 8000.
* `-v $(pwd)/chroma_data:/chroma/chroma` mounts a local directory for persistent storage.
* `chromadb/chroma` is the official Chroma image.

### Connecting from Python to Docker Chroma

```python
import chromadb

client = chromadb.HttpClient(host="localhost", port=8000)
collection = client.get_or_create_collection("docker_demo")
```

This setup allows you to use Chroma as a **standalone service**, decoupled from your Python runtime.

---

## Managing Large Datasets

When working with larger corpora (millions of documents), you should optimize how data is ingested and queried.

1. **Batch Inserts** – Instead of adding documents one by one, use batches:

   ```python
   documents = ["doc " + str(i) for i in range(10000)]
   ids = ["id" + str(i) for i in range(10000)]
   collection.add(documents=documents, ids=ids)
   ```

2. **Efficient Embedding Computation** – Pre-compute embeddings using a library like HuggingFace or OpenAI, and then insert them:

   ```python
   from sentence_transformers import SentenceTransformer
   model = SentenceTransformer("all-MiniLM-L6-v2")

   texts = ["deep learning", "vector search"]
   embeddings = model.encode(texts).tolist()

   collection.add(documents=texts, embeddings=embeddings, ids=["t1", "t2"])
   ```

3. **Indexing and Querying** – Chroma automatically manages indexes, but query performance depends on dataset size and hardware. For very large datasets, consider scaling with a distributed vector DB (e.g., Qdrant, Weaviate, Pinecone).

---

## Exporting & Importing Collections

Chroma lets you back up or migrate collections between environments.

### Exporting

```python
client = chromadb.PersistentClient(path="chroma_store")
collection = client.get_collection("my_docs")

# Export collection to JSON
export_data = collection.get(include=["documents", "embeddings", "metadatas"])
import json
with open("backup.json", "w") as f:
    json.dump(export_data, f)
```

### Importing

```python
import json
with open("backup.json", "r") as f:
    data = json.load(f)

new_collection = client.create_collection("my_docs_restored")
new_collection.add(
    ids=data["ids"],
    documents=data["documents"],
    embeddings=data["embeddings"],
    metadatas=data["metadatas"]
)
```

This makes it easy to transfer collections across machines or reload from a backup.

---

## Key Takeaways

* Use **PersistentClient with SQLite** to retain data across sessions.
* Deploy Chroma using **Docker** for scalable and portable workflows.
* Optimize large dataset ingestion with **batch inserts and pre-computed embeddings**.
* Use **export/import** for backup and migration of collections.

---

