# Chapter 4: Connecting Streamlit with LangChain / LangGraph Agents

Now that we’ve covered Streamlit basics and multi-agent dashboards, let’s connect our Streamlit interface with **LangChain** and **LangGraph** back-ends. This chapter focuses on integrating Streamlit’s front-end capabilities with agent pipelines so that queries entered by a user can be processed by agents, and results displayed in a structured, interactive way.

---

## 4.1 Why Connect Streamlit with LangChain / LangGraph?

* **Streamlit** provides a simple, fast way to build user interfaces.
* **LangChain** gives you agentic workflows, tool integration, and LLM orchestration.
* **LangGraph** enables graph-based pipelines with explicit states and branching logic.

By connecting them, you can:

* Expose agents to non-technical users via a web UI.
* Collect structured inputs from Streamlit widgets and pass them to agent pipelines.
* Display agent outputs in user-friendly formats like tables, cards, or expandable sections.

---

## 4.2 General Integration Pattern

1. **Collect input in Streamlit**
   Example: patient symptoms, lab test request, or customer query.

2. **Pass input to LangChain / LangGraph agent**
   Use API calls or Python function calls inside Streamlit to trigger agent workflows.

3. **Get structured results from the agent**
   The agent outputs JSON, dicts, or text.

4. **Render results in Streamlit**
   Tables (`st.table`), JSON (`st.json`), or custom UI layouts (`st.columns`, `st.expander`).

---

## 4.3 Example: Connecting Streamlit to a LangGraph Test Order Placer Agent

We’ll simulate a **Test Order Placer Agent** that takes a symptom description and recommends lab tests.

### Agent (Backend) Simulation

```python
# test_order_agent.py
def test_order_agent(symptoms: str) -> dict:
    """
    A dummy Test Order Placer Agent.
    Takes symptom text and returns suggested lab tests.
    """
    # Simple rule-based mapping (replace with LangGraph pipeline in production)
    if "cough" in symptoms.lower():
        return {"tests": ["Chest X-Ray", "CBC", "Sputum Culture"]}
    elif "fatigue" in symptoms.lower():
        return {"tests": ["Thyroid Panel", "Vitamin D", "CBC"]}
    else:
        return {"tests": ["General Health Checkup Panel"]}
```

---

### Streamlit Front-End

```python
# streamlit_app.py
import streamlit as st
from test_order_agent import test_order_agent

st.title("Test Order Placer Agent (Demo)")

# Step 1: Collect Input
symptoms = st.text_area("Enter patient symptoms:")

if st.button("Get Suggested Tests"):
    # Step 2: Send to Agent
    results = test_order_agent(symptoms)

    # Step 3: Display Results
    st.subheader("Suggested Lab Tests")
    st.table({"Test Name": results["tests"]})
```

---

### Output (User Experience)

1. The user enters:

   ```
   Patient reports persistent cough and mild fever.
   ```
2. Clicks **"Get Suggested Tests"**.
3. The app shows:

| Test Name      |
| -------------- |
| Chest X-Ray    |
| CBC            |
| Sputum Culture |

---

## 4.4 Extending with LangGraph

In a real pipeline, instead of the dummy `test_order_agent`, you’d connect to a **LangGraph workflow**:

```python
from langgraph.graph import StateGraph

# Define graph state
graph = StateGraph()

# Example: Node for test ordering
def order_tests(state):
    symptoms = state["symptoms"]
    return {"tests": ["Automated pipeline would decide here"]}

graph.add_node("order_tests", order_tests)
graph.set_entry_point("order_tests")

# In Streamlit:
results = graph.invoke({"symptoms": symptoms})
st.json(results)
```

---

## 4.5 Best Practices

* Keep the **UI and agent logic separate** (e.g., `test_order_agent.py` for logic, `streamlit_app.py` for UI).
* Validate inputs in Streamlit before sending them to the agent.
* Display results in structured formats (tables, expanders, JSON viewers).
* For production:

  * Use async calls if agent responses are long.
  * Cache results (`st.cache_data`) for repeated queries.

---

