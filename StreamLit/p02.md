# Chapter 2: Streamlit Basics for Agent Interaction

In the previous chapter, we introduced Streamlit and explored why it is well-suited for building Agentic Systems. Now, let’s take a step further and learn how to interact with users through Streamlit’s core widgets, and how to handle simple input/output flows in the context of an agent-driven application.

---

## 2.1 Widgets for Agent Interaction

Streamlit provides a wide range of widgets to capture user input and display outputs. For agentic use cases, some key widgets are:

* **`st.text_input`** – Allows the user to enter free text (useful for queries, symptoms, prompts).
* **`st.button`** – Captures an action trigger (e.g., “Submit” or “Ask Agent”).
* **`st.selectbox`** – Presents predefined options (e.g., choosing a symptom category).
* **`st.chat_message`** – (new in Streamlit 1.25+) enables a chat-like conversational UI, ideal for multi-turn agent interactions.

These widgets make it easy to build a simple but powerful front-end for agents.

---

## 2.2 Handling Input/Output Flows

A typical flow in an agentic app is:

1. **User Input** – The user provides a query or symptom.
2. **Processing** – The query is passed to an agent (dummy or real).
3. **Agent Response** – The response is displayed back in the UI.

Streamlit makes this seamless because:

* Inputs are reactive: when a user types or clicks, the app reruns with updated values.
* Outputs can be dynamically updated in the layout.
* Session state (`st.session_state`) can be used to remember conversation history across reruns.

---

## 2.3 Example: Symptom Triage Chat

Here’s a minimal example where a user asks a symptom-related question and a **dummy triage agent** responds with a canned answer.

```python
import streamlit as st

st.title("🤖 Symptom Triage Agent")

# Initialize chat history in session_state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display previous messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input (user's symptom-related query)
if prompt := st.chat_input("Describe your symptom..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Dummy agent response (replace with real agent later)
    response = "This is a triage agent. Based on your input, I suggest consulting a doctor if symptoms persist."
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
```

---

### What this app does:

* Maintains a **chat history** with `st.session_state`.
* Uses `st.chat_input` and `st.chat_message` to create a chat-like UI.
* Responds with a **dummy triage agent answer** (placeholder for real logic).

When you run the app with `streamlit run app.py`, you’ll get an interactive chat interface where users can type in symptoms and receive an automated response.

---

✅ **Key takeaway**:
With just a few lines of Streamlit code, you can simulate a chatbot-style triage agent. Later chapters will show how to plug in real LLM agents, medical logic, and external APIs.

---

