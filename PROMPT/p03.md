# 3. **Core Prompting Techniques**

Prompt engineering relies on a set of fundamental techniques that determine how effectively a large language model (LLM) interprets and generates outputs. These techniques shape the quality, reliability, and relevance of responses, making them essential skills for practitioners.

---

## 3.1 Zero-Shot Prompting

**Definition:**
Zero-shot prompting is when you ask the model to perform a task without providing any examples. Instead, you rely entirely on clear instructions.

**Example:**

> *Prompt:* “Translate the following English sentence into French: ‘The weather is nice today.’”

**Advantages:**

* Simple and efficient.
* Works well for general tasks the model has already been trained on.

**Limitations:**

* May produce inconsistent results for complex or niche tasks.
* Relies heavily on how precisely the instruction is phrased.

---

## 3.2 Few-Shot Prompting with Examples

**Definition:**
Few-shot prompting provides the model with one or more examples of input-output pairs before asking it to perform the task. This gives the model context and helps it generalize to similar cases.

**Example:**

> *Prompt:*
> “Translate English to French:
>
> * English: ‘Good morning’ → French: ‘Bonjour’
> * English: ‘Thank you’ → French: ‘Merci’
> * English: ‘How are you?’ → French: ”

**Advantages:**

* Provides guidance on the expected style, tone, and format.
* Reduces ambiguity compared to zero-shot prompts.

**Limitations:**

* Requires careful selection of examples.
* Longer prompts may hit context window limits.

---

## 3.3 Instruction-Based Prompting

**Definition:**
Instruction-based prompting focuses on giving the model direct commands, often in natural language. This method leverages instruction-tuned LLMs (like ChatGPT) that are optimized to follow explicit directions.

**Example:**

> *Prompt:* “Summarize this article in three bullet points, using simple language suitable for a high school student.”

**Advantages:**

* Very flexible; can handle a wide range of tasks.
* Particularly effective with models trained on instruction-following datasets.

**Limitations:**

* If the instruction is vague, the output may drift from the intended goal.

---

## 3.4 Chain-of-Thought Prompting (Reasoning Prompts)

**Definition:**
Chain-of-thought (CoT) prompting encourages the model to “think out loud” by breaking down reasoning into intermediate steps before producing the final answer.

**Example:**

> *Prompt:* “A store sells apples for \$2 each and oranges for \$3 each. If John buys 3 apples and 2 oranges, how much does he pay? Please explain step by step before giving the final answer.”

**Advantages:**

* Improves accuracy on tasks requiring logical reasoning or calculations.
* Makes the reasoning process transparent.

**Limitations:**

* Can increase verbosity.
* May still produce flawed reasoning chains if the model is biased or under-trained in logic.

---

## 3.5 Self-Consistency Prompting

**Definition:**
Self-consistency prompting improves reasoning tasks by sampling multiple reasoning paths and then selecting the most consistent final answer. Instead of relying on a single chain-of-thought, the model generates several, and the most common answer is chosen.

**Example Workflow:**

1. Ask the model to solve a problem multiple times with reasoning steps.
2. Collect all final answers.
3. Choose the answer that appears most frequently.

**Advantages:**

* Reduces random errors in reasoning.
* Boosts performance on complex tasks like math or commonsense reasoning.

**Limitations:**

* Requires multiple generations (higher compute cost).
* Best used when accuracy is critical and resources allow.

---

## Key Takeaways

* **Zero-shot prompting** is simple but can be inconsistent.
* **Few-shot prompting** benefits from carefully chosen examples.
* **Instruction-based prompting** leverages natural commands for clarity.
* **Chain-of-thought prompting** strengthens reasoning by making it explicit.
* **Self-consistency prompting** aggregates multiple reasoning paths for more reliable answers.

Together, these techniques form the **core toolbox of prompt engineering**, enabling practitioners to design effective prompts for diverse tasks.

---

