# **Chapter 12 — Building a Unified Dashboard**

### **Overview**

In this chapter, we will **merge the user interface (Streamlit or Dash)** with the **FastAPI backend** to create a unified, interactive dashboard. This integration allows you to control backend AI models (via LangServe endpoints), manage database operations, and visualize progress or responses in real time.

We’ll explore how to:

* Integrate Streamlit or Dash with FastAPI APIs
* Use WebSockets or Server-Sent Events (SSE) for real-time updates
* Embed LangServe model endpoints (like `/api/diagnose`, `/api/summarize`) in the dashboard

---

## **12.1 Understanding the Unified Architecture**

Before writing code, it’s important to visualize the **architecture flow**:

```
 ┌────────────────────────────┐
 │        Frontend UI         │
 │ (Streamlit or Dash App)    │
 │                            │
 │  - User Inputs             │
 │  - Display AI Outputs      │
 │  - Show Progress           │
 └────────────┬───────────────┘
              │
              │  REST / WebSocket / SSE
              ▼
 ┌────────────────────────────┐
 │         FastAPI App        │
 │ - CRUD Endpoints           │
 │ - LangServe Routes         │
 │   (/api/diagnose, /api/summarize)  
 │ - WebSocket Manager        │
 └────────────┬───────────────┘
              │
              ▼
 ┌────────────────────────────┐
 │       LangChain Logic      │
 │ - LLM Chains / Agents      │
 │ - Tools (SQL, APIs, etc.)  │
 └────────────────────────────┘
```

---

## **12.2 Streamlit Integration with FastAPI**

Let’s first use **Streamlit** to call your FastAPI + LangServe endpoints.

### **Step 1 — Setting up the FastAPI server**

Suppose your backend exposes:

* `/api/diagnose` → LangServe chain for medical diagnosis
* `/api/summarize` → LangServe summarization chain

```python
# app/main.py (FastAPI backend)
from fastapi import FastAPI
from langserve import add_routes
from my_chains import diagnose_chain, summarize_chain

app = FastAPI()

add_routes(app, diagnose_chain, path="/api/diagnose")
add_routes(app, summarize_chain, path="/api/summarize")
```

Run this backend with:

```bash
uvicorn app.main:app --reload
```

---

### **Step 2 — Streamlit Frontend**

Create a simple dashboard that interacts with these endpoints.

```python
# streamlit_app.py
import streamlit as st
import requests

st.title("Unified Health AI Dashboard")

backend_url = "http://127.0.0.1:8000"

tab1, tab2 = st.tabs(["Diagnose", "Summarize"])

with tab1:
    st.subheader("Patient Diagnosis")
    symptoms = st.text_area("Enter symptoms")
    if st.button("Run Diagnosis"):
        with st.spinner("Running AI diagnosis..."):
            res = requests.post(f"{backend_url}/api/diagnose/invoke",
                                json={"input": {"symptoms": symptoms}})
            st.json(res.json())

with tab2:
    st.subheader("Medical Summary")
    report_text = st.text_area("Paste report text")
    if st.button("Summarize Report"):
        with st.spinner("Generating summary..."):
            res = requests.post(f"{backend_url}/api/summarize/invoke",
                                json={"input": {"text": report_text}})
            st.json(res.json())
```

Now run Streamlit:

```bash
streamlit run streamlit_app.py
```

✅ You’ll see a unified interface that sends user inputs to your **LangServe chains** and displays structured JSON outputs.

---

## **12.3 Dash Integration with FastAPI**

If you prefer **Dash**, the approach is similar but uses callbacks.

```python
# dash_app.py
from dash import Dash, html, dcc, Input, Output, State
import requests
import dash_bootstrap_components as dbc

app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
server = app.server  # exposes FastAPI server if needed

backend_url = "http://127.0.0.1:8000"

app.layout = dbc.Container([
    html.H2("Unified AI Dashboard"),
    dbc.Tabs([
        dbc.Tab(label="Diagnosis", tab_id="diagnosis"),
        dbc.Tab(label="Summary", tab_id="summary")
    ], id="tabs", active_tab="diagnosis"),
    html.Div(id="content")
])

@app.callback(Output("content", "children"), Input("tabs", "active_tab"))
def render_tab(tab):
    if tab == "diagnosis":
        return html.Div([
            html.H4("AI Diagnosis"),
            dcc.Textarea(id="symptoms", style={"width":"100%"}),
            html.Br(),
            html.Button("Run Diagnosis", id="run_diag"),
            html.Div(id="diag_output")
        ])
    else:
        return html.Div([
            html.H4("Summary Generator"),
            dcc.Textarea(id="report", style={"width":"100%"}),
            html.Br(),
            html.Button("Summarize", id="run_summary"),
            html.Div(id="summary_output")
        ])

@app.callback(Output("diag_output", "children"),
              Input("run_diag", "n_clicks"),
              State("symptoms", "value"),
              prevent_initial_call=True)
def run_diagnosis(n, symptoms):
    res = requests.post(f"{backend_url}/api/diagnose/invoke", json={"input": {"symptoms": symptoms}})
    return str(res.json())

@app.callback(Output("summary_output", "children"),
              Input("run_summary", "n_clicks"),
              State("report", "value"),
              prevent_initial_call=True)
def summarize(n, report):
    res = requests.post(f"{backend_url}/api/summarize/invoke", json={"input": {"text": report}})
    return str(res.json())

if __name__ == "__main__":
    app.run_server(debug=True)
```

---

## **12.4 Real-Time Progress Updates**

If your LangChain process takes time (e.g., multiple reasoning steps), you can use:

### **Option A — WebSockets**

FastAPI provides built-in WebSocket support:

```python
# app/main.py
from fastapi import WebSocket
import asyncio

@app.websocket("/ws/progress")
async def progress_socket(ws: WebSocket):
    await ws.accept()
    for i in range(5):
        await ws.send_json({"progress": f"{(i+1)*20}%"})
        await asyncio.sleep(1)
    await ws.close()
```

Frontend (Streamlit example):

```python
import streamlit as st
import asyncio
import websockets
import json

async def stream_progress():
    uri = "ws://127.0.0.1:8000/ws/progress"
    async with websockets.connect(uri) as websocket:
        while True:
            msg = await websocket.recv()
            data = json.loads(msg)
            st.write(data["progress"])

if st.button("Start Process"):
    asyncio.run(stream_progress())
```

---

### **Option B — Server-Sent Events (SSE)**

If you want one-way streaming instead of bidirectional communication:

**FastAPI Backend:**

```python
from fastapi.responses import StreamingResponse
import time

@app.get("/stream")
def stream():
    def event_stream():
        for i in range(5):
            yield f"data: Progress {i*20}%\n\n"
            time.sleep(1)
    return StreamingResponse(event_stream(), media_type="text/event-stream")
```

**Streamlit Frontend:**

```python
import streamlit as st
import requests

st.write("Connecting to event stream...")
res = requests.get("http://127.0.0.1:8000/stream", stream=True)
for line in res.iter_lines():
    if line:
        st.write(line.decode("utf-8"))
```

---

## **12.5 Embedding LangServe Endpoints**

LangServe exposes model endpoints like:

* `/api/diagnose/invoke`
* `/api/summarize/invoke`
* `/api/chat/invoke`

These endpoints can easily be **embedded** into the UI.

For instance:

* Call `/api/diagnose/invoke` from Streamlit to show a **symptom analysis**
* Call `/api/summarize/invoke` to display a **medical summary**
* Use `/api/chat/invoke` to enable **interactive AI conversation**

Each call can send structured JSON input and receive an AI-generated JSON response.

Example:

```json
POST /api/diagnose/invoke
{
  "input": {
    "symptoms": "fever, cough, and fatigue for 3 days"
  }
}
```

Response:

```json
{
  "output": {
    "possible_conditions": ["Viral Infection", "Influenza"],
    "recommendations": ["Hydration", "Paracetamol 500mg", "Rest"]
  }
}
```

---

## **12.6 Summary**

In this chapter, you learned how to:

* Combine **FastAPI backend** with **Streamlit or Dash frontend**
* Stream real-time updates using **WebSocket/SSE**
* Embed **LangServe endpoints** for model-driven workflows

This unified dashboard architecture lets you build a **professional-grade AI control panel** for diagnostics, summarization, or other intelligent applications.

---

