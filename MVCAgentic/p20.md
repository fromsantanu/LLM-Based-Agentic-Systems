# **Chapter 20: Packaging & Deployment**

### **Overview**

After developing your complete system — combining **LangServe**, **FastAPI**, and a **Streamlit or Dash UI** — the next crucial step is to **package** and **deploy** it efficiently.
In this chapter, you’ll learn how to:

1. **Dockerize** the full stack (API + LangServe + UI).
2. **Deploy** it using `uvicorn` or `gunicorn`.
3. Configure a **reverse proxy** (like Nginx) for unified access to `/api` and `/dashboard`.

---

## **20.1 Understanding Deployment Structure**

Your final project stack typically looks like this:

```
project_root/
│
├── app/
│   ├── main.py              ← FastAPI + LangServe endpoints
│   ├── models.py
│   ├── routes/
│   └── services/
│
├── dashboard/
│   ├── app.py               ← Streamlit or Dash UI
│
├── requirements.txt
├── Dockerfile
├── docker-compose.yml
└── nginx/
    └── nginx.conf
```

This structure allows:

* **FastAPI/LangServe** backend served on `/api`
* **UI Dashboard** on `/dashboard`
* **Single entry point** via Nginx reverse proxy

---

## **20.2 Dockerizing the Complete System**

### **Step 1: Create a Dockerfile**

Below is a multi-stage build example combining backend and frontend.

```dockerfile
# Stage 1: Build environment
FROM python:3.11-slim AS base
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Stage 2: Copy project
COPY . .

# Expose port for FastAPI
EXPOSE 8000

# Default command (FastAPI + LangServe)
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

✅ **Alternative:**
If your frontend (e.g., Streamlit or Dash) runs separately, create a second container:

* **Container 1**: FastAPI + LangServe (`:8000`)
* **Container 2**: Streamlit or Dash (`:8501`)
* **Container 3**: Nginx reverse proxy (`:80`)

---

## **20.3 Using Docker Compose**

Create `docker-compose.yml` for a unified deployment:

```yaml
version: "3.9"
services:
  backend:
    build: .
    container_name: langserve_backend
    ports:
      - "8000:8000"
    restart: always

  dashboard:
    build:
      context: .
      dockerfile: dashboard/Dockerfile
    container_name: dashboard_ui
    ports:
      - "8501:8501"
    restart: always

  nginx:
    image: nginx:alpine
    container_name: nginx_proxy
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - backend
      - dashboard
```

---

## **20.4 Nginx Reverse Proxy Configuration**

Create `nginx/nginx.conf` to route traffic to respective services.

```nginx
events {}

http {
    server {
        listen 80;

        location /api/ {
            proxy_pass http://backend:8000/;
            proxy_set_header Host $host;
        }

        location /dashboard/ {
            proxy_pass http://dashboard:8501/;
            proxy_set_header Host $host;
        }

        location / {
            return 302 /dashboard/;
        }
    }
}
```

Now both systems are accessible via:

```
http://localhost/api
http://localhost/dashboard
```

---

## **20.5 Running the Deployment**

### **Option 1: Using Docker Compose**

```bash
docker-compose up --build
```

This command:

* Builds the containers
* Starts FastAPI + LangServe backend
* Starts Streamlit/Dash frontend
* Routes everything through Nginx

Visit:

```
http://localhost/dashboard
```

---

### **Option 2: Manual Deployment with Uvicorn**

If you’re not using Docker yet:

```bash
# Run FastAPI + LangServe
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Run your UI separately:

```bash
# Streamlit
streamlit run dashboard/app.py --server.port 8501
# OR Dash
python dashboard/app.py
```

You can still place **Nginx** in front of both processes for unified routing.

---

## **20.6 Using Gunicorn (Production Grade)**

While `uvicorn` is great for development, **Gunicorn with Uvicorn workers** provides production reliability.

Install:

```bash
pip install gunicorn uvicorn
```

Run:

```bash
gunicorn app.main:app -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000 --workers 4
```

✅ **Advantages:**

* Handles concurrency better
* Graceful restarts
* Scales across CPU cores

---

## **20.7 Environment Configuration**

Use `.env` for managing environment variables:

```
DB_URL=postgresql://user:password@db:5432/healthdb
OPENAI_API_KEY=sk-xxxx
MODE=production
```

Update your FastAPI app to load it:

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    db_url: str
    openai_api_key: str
    mode: str = "dev"

    class Config:
        env_file = ".env"

settings = Settings()
```

---

## **20.8 Health Check and Logs**

Add a simple health route in FastAPI:

```python
@app.get("/health")
def health():
    return {"status": "ok"}
```

Check logs from running containers:

```bash
docker logs langserve_backend
docker logs dashboard_ui
```

---

## **20.9 Deployment Targets**

You can deploy this containerized system on:

| Platform                       | Notes                                   |
| ------------------------------ | --------------------------------------- |
| **AWS ECS / Fargate**          | Best for scalable multi-container setup |
| **Azure Container Apps**       | Simple cloud-native hosting             |
| **Google Cloud Run**           | Auto-scaling container runtime          |
| **Railway / Render / Fly.io**  | Easy for hobby or demo deployments      |
| **Local VM (Ubuntu + Docker)** | Perfect for testing and intranet setups |

---

## **20.10 Summary**

| Topic                     | Description                               |
| ------------------------- | ----------------------------------------- |
| **Dockerization**         | Encapsulates environment and dependencies |
| **Docker Compose**        | Simplifies multi-container orchestration  |
| **Nginx Proxy**           | Provides unified endpoint for UI and API  |
| **Gunicorn + Uvicorn**    | Recommended for production                |
| **Environment Variables** | Securely manage keys and configs          |
| **Cloud Deployments**     | Scale your system with minimal setup      |

---

### ✅ **Key Takeaway**

> **LangServe + FastAPI + Streamlit/Dash** can be packaged into a clean, containerized stack that’s production-ready, portable, and easy to scale.
> Proper use of Nginx and environment configurations ensures a unified and secure deployment environment.

---
