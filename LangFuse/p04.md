# Chapter 4: Integrating LangFuse with Frameworks

Once you understand the basics of observability and instrumentation, the next step is to integrate LangFuse with the frameworks you’re already using to build Agentic AI applications. LangFuse provides flexible APIs and SDKs that make it easy to capture traces, spans, and events across LangChain, LangGraph, and even custom Python agents.

---

## 4.1 LangChain Integration

LangChain is one of the most widely used frameworks for building agentic workflows, and LangFuse provides first-class support for it.

### Using the `@traceable` decorator

* Wrap LLM calls, tools, or custom chains with `@traceable`.
* This automatically creates a trace in LangFuse for each invocation.
* Example:

```python
from langfuse.decorators import traceable
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model="gpt-4")

@traceable
def generate_summary(text: str) -> str:
    return llm.predict(f"Summarize this: {text}")
```

### Callbacks for advanced workflows

* Use LangFuse’s callback handler to automatically capture inputs, outputs, and metadata.
* Example:

```python
from langfuse.callback import CallbackHandler
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

handler = CallbackHandler()
prompt = PromptTemplate.from_template("Translate this into French: {sentence}")

chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])

result = chain.run("How are you?")
```

This will log the full chain execution (prompt, LLM response, metadata) into LangFuse.

---

## 4.2 LangGraph Integration

LangGraph introduces structured, stateful workflows where observability is critical.

* With LangFuse, you can **capture each state transition as a span**.
* Each graph node or edge execution is recorded with context: input → output → state update.
* Example:

```python
from langfuse.decorators import traceable

@traceable
def classify_symptom(symptom: str) -> str:
    # Node function in LangGraph
    if "fever" in symptom:
        return "Triage → High Priority"
    return "Triage → Normal"
```

When used inside a LangGraph workflow, every node call produces a span in the LangFuse dashboard, letting you visualize the path taken through the graph.

---

## 4.3 Direct Python SDK Instrumentation

If you’re not using LangChain or LangGraph—or if you’ve built a **custom agent**—you can instrument code directly using the Python SDK.

* Create a trace explicitly.
* Add spans for intermediate steps.
* Log outputs, errors, and metadata.

```python
from langfuse import Langfuse

lf = Langfuse()

trace = lf.trace(name="custom-agent", user_id="user-123")

with trace.span(name="reasoning-step") as span:
    span.log_input({"question": "What is 2+2?"})
    result = 2 + 2
    span.log_output({"answer": result})
```

This approach gives you maximum flexibility when frameworks don’t provide built-in integration.

---

## 4.4 Using LangFuse with FastAPI and Streamlit

Agentic AI applications often need to be **interactive**. LangFuse can be integrated into web frameworks to capture user interactions and backend reasoning.

### FastAPI Example

Attach LangFuse tracing inside your endpoints:

```python
from fastapi import FastAPI
from langfuse.decorators import traceable

app = FastAPI()

@traceable
@app.post("/summarize")
async def summarize(request: dict):
    text = request["text"]
    return {"summary": f"Summary of: {text}"}
```

This lets you link **frontend requests → backend traces** in LangFuse.

### Streamlit Example

For rapid prototyping and dashboards:

```python
import streamlit as st
from langfuse.decorators import traceable

@traceable
def chatbot_response(prompt: str) -> str:
    return f"Echo: {prompt}"

st.title("LangFuse + Streamlit Chatbot")
user_input = st.text_input("Ask me something:")
if user_input:
    response = chatbot_response(user_input)
    st.write(response)
```

Here, every Streamlit interaction is tracked in LangFuse, giving you visibility into user queries and agent responses.

---

✅ **Summary:**

* **LangChain** → use `@traceable` and callbacks.
* **LangGraph** → capture state transitions as spans.
* **Custom Python** → use the SDK directly.
* **FastAPI / Streamlit** → wrap endpoints or UI handlers for end-to-end visibility.

With these integrations, you can build interactive, production-ready AI systems while monitoring their behavior in real time.

---

