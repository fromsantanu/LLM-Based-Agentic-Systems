# Chapter 19: Microservices & Scaling

As applications grow, it becomes important to break them into **smaller, independent services** rather than building a large monolithic app. This is where **microservices** and scaling strategies come in.

FastAPI is well-suited for building microservices because of its speed, asynchronous support, and flexibility.

---

## üöÄ Why Microservices?

* **Scalability**: Each service can be scaled independently.
* **Fault isolation**: A failure in one service doesn‚Äôt bring down the whole system.
* **Flexibility**: Services can use different databases, frameworks, or even programming languages.
* **Deployment**: Teams can deploy services independently.

---

## üê≥ FastAPI in Docker

Docker is commonly used to package microservices for easy deployment.

**Dockerfile for FastAPI:**

```dockerfile
# Use official Python base image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy project files
COPY . .

# Run FastAPI app with Uvicorn
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**requirements.txt**

```
fastapi
uvicorn[standard]
```

**Build and Run**

```bash
docker build -t fastapi-microservice .
docker run -d -p 8000:8000 fastapi-microservice
```

Now your service is containerized and ready for deployment.

---

## üîÄ API Gateway Design with FastAPI

In microservices architecture, an **API Gateway** acts as a single entry point for clients.
It routes requests to the right microservice.

**Example: Simple API Gateway in FastAPI**

```python
from fastapi import FastAPI
import httpx

app = FastAPI()

@app.get("/payments/{user_id}")
async def get_payment(user_id: int):
    async with httpx.AsyncClient() as client:
        response = await client.get(f"http://payments-service:8000/payments/{user_id}")
    return response.json()

@app.get("/orders/{order_id}")
async def get_order(order_id: int):
    async with httpx.AsyncClient() as client:
        response = await client.get(f"http://orders-service:8000/orders/{order_id}")
    return response.json()
```

Here:

* Clients call the gateway (instead of calling each service directly).
* The gateway proxies requests to services (Payments, Orders, etc.).

---

## üîó Service-to-Service Communication

Microservices often need to **talk to each other**. Two common approaches are:

### 1. REST (HTTP + JSON)

* Easy to implement.
* Works with any language.
* Higher overhead due to JSON serialization.

Example (Payment Service calling Order Service):

```python
import httpx

async def notify_order_service(order_id: int, status: str):
    async with httpx.AsyncClient() as client:
        await client.post("http://orders-service:8000/update_status", 
                          json={"order_id": order_id, "status": status})
```

---

### 2. gRPC (Binary Protocol)

* Faster, smaller payloads.
* Strong typing with Protocol Buffers.
* Requires both services to implement gRPC.

**Proto File (`payment.proto`):**

```proto
syntax = "proto3";

service PaymentService {
  rpc ProcessPayment (PaymentRequest) returns (PaymentResponse);
}

message PaymentRequest {
  int32 user_id = 1;
  double amount = 2;
}

message PaymentResponse {
  bool success = 1;
  string message = 2;
}
```

**Run protoc to generate Python gRPC code**:

```bash
python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. payment.proto
```

FastAPI service can run gRPC server in a separate process (or with asyncio + grpc.aio).

---

## üí≥ Example: Payments Microservice with FastAPI

**payments_service.py**

```python
from fastapi import FastAPI, HTTPException

app = FastAPI()

fake_db = {"user1": 500.0, "user2": 300.0}

@app.post("/payments/{user_id}")
async def process_payment(user_id: str, amount: float):
    if user_id not in fake_db:
        raise HTTPException(status_code=404, detail="User not found")

    if fake_db[user_id] < amount:
        raise HTTPException(status_code=400, detail="Insufficient funds")

    fake_db[user_id] -= amount
    return {"status": "success", "remaining_balance": fake_db[user_id]}
```

---

## ‚ö° Scaling Microservices

1. **Horizontal scaling**: Run multiple instances of the same service (e.g., via Kubernetes, Docker Swarm).
2. **Load balancing**: Distribute traffic using Nginx, HAProxy, or a cloud load balancer.
3. **Service discovery**: Use tools like Consul or Kubernetes DNS to let services find each other.
4. **Message queues**: For async communication between services (RabbitMQ, Kafka).

---

‚úÖ **Key Takeaways**

* FastAPI is ideal for microservices because it‚Äôs lightweight and async.
* Use Docker to containerize and deploy services.
* API Gateway simplifies client access to multiple services.
* Services can communicate via REST or gRPC depending on performance needs.
* Scaling strategies involve replication, load balancing, and service discovery.

---

