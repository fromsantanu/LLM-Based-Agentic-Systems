# **Chapter 20: Deployment**

## **Topics Covered**

* Using **Docker** to containerize your SQLAlchemy application
* Setting up **PostgreSQL** as the production database
* Running **Alembic migrations automatically** on container startup
* Managing **environment variables securely**

---

## **1. Introduction**

After development and testing, deploying your SQLAlchemy-based project in a reproducible, portable, and secure way is critical.
This chapter covers how to use **Docker** and **Docker Compose** for deployment, how to integrate **PostgreSQL** as your production database, and how to manage migrations and environment variables effectively.

---

## **2. Dockerizing Your Application**

### **Step 1: Create a Dockerfile**

Below is an example `Dockerfile` for a **FastAPI + SQLAlchemy** application.

```dockerfile
# Use an official Python image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y libpq-dev gcc && apt-get clean

# Copy requirement file
COPY requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy project files
COPY . .

# Set environment variable
ENV PYTHONUNBUFFERED=1

# Run app (you can replace with your own start command)
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

### **Step 2: Create a Docker Compose File**

`docker-compose.yml` helps manage multi-container setups (App + Database + Alembic).

```yaml
version: '3.9'

services:
  db:
    image: postgres:15
    container_name: my_postgres
    restart: always
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  web:
    build: .
    container_name: my_web_app
    depends_on:
      - db
    environment:
      DATABASE_URL: postgresql+psycopg2://myuser:mypassword@db:5432/mydb
      ENVIRONMENT: production
    ports:
      - "8000:8000"
    command: bash -c "alembic upgrade head && uvicorn main:app --host 0.0.0.0 --port 8000"

volumes:
  postgres_data:
```

âœ… **Key points:**

* The web container waits for the `db` service.
* Alembic migration runs **automatically** before the app starts.
* Persistent storage via `postgres_data` volume.

---

## **3. Running Alembic Migrations Automatically**

In production, you often need to **run migrations automatically** when the container starts.

You can achieve this with a custom **entrypoint script**.

### **entrypoint.sh**

```bash
#!/bin/bash
echo "Waiting for PostgreSQL to start..."
sleep 5

echo "Running migrations..."
alembic upgrade head

echo "Starting the app..."
exec "$@"
```

### Update your `Dockerfile`:

```dockerfile
COPY entrypoint.sh /app/
RUN chmod +x /app/entrypoint.sh
ENTRYPOINT ["/app/entrypoint.sh"]
```

### Update `docker-compose.yml`:

```yaml
command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Now, every time your app container starts, Alembic applies any new migrations automatically.

---

## **4. Managing Environment Variables Securely**

### **.env File**

You should **never hardcode secrets** (like database passwords) inside your code or YAML files.
Use a `.env` file to manage environment variables:

```
POSTGRES_USER=myuser
POSTGRES_PASSWORD=mypassword
POSTGRES_DB=mydb
DATABASE_URL=postgresql+psycopg2://myuser:mypassword@db:5432/mydb
SECRET_KEY=super_secret_key
```

### **Using the .env file in docker-compose.yml**

```yaml
env_file:
  - .env
```

### **Using Pythonâ€™s `python-dotenv`**

If running locally or outside Docker, load `.env` automatically:

```python
from dotenv import load_dotenv
import os

load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")
SECRET_KEY = os.getenv("SECRET_KEY")
```

---

## **5. Verifying Deployment**

### **Run Containers**

```bash
docker-compose up --build
```

### **Check Logs**

```bash
docker-compose logs -f
```

You should see:

```
Running migrations...
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Running upgrade -> head
Starting the app...
```

### **Visit Your App**

ðŸ‘‰ Open [http://localhost:8000](http://localhost:8000)

---

## **6. Production Considerations**

| Area                      | Recommendation                                        |
| ------------------------- | ----------------------------------------------------- |
| **Database**              | Use managed PostgreSQL (AWS RDS, Azure, GCP)          |
| **Environment Variables** | Use Docker secrets or cloud secret managers           |
| **Logging**               | Configure structured logs (JSON format for ELK stack) |
| **Scaling**               | Use Kubernetes or Docker Swarm                        |
| **Monitoring**            | Integrate Prometheus + Grafana or CloudWatch          |
| **Backups**               | Automate PostgreSQL dump to cloud storage             |

---

## **7. Example Directory Structure**

```
my_project/
â”œâ”€â”€ alembic/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ database.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ entrypoint.sh
â”œâ”€â”€ .env
â””â”€â”€ requirements.txt
```

---

## **8. Summary**

âœ… You learned how to:

* Containerize your SQLAlchemy + FastAPI application using Docker
* Integrate PostgreSQL as a production database
* Run Alembic migrations automatically on container startup
* Manage environment variables securely

---

### **Next Steps**

* Configure CI/CD pipeline to build and push Docker images to a registry (GitHub Actions / GitLab CI)
* Deploy containers on a cloud platform (AWS ECS, Azure Container Apps, or Render)

---
