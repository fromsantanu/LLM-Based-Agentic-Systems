# Chapter 15 — Using SQLAlchemy with Databases

*SQLite for local work • Postgres & MySQL setup • Connection pooling done right (sync & async)*

---

## 15.1 Overview

By now you’ve built models, queries, sessions, and migrations. Time to wire your app to real databases—locally (SQLite) and in production (PostgreSQL/MySQL)—with sane connection-pool settings and deployment patterns.

**What you’ll learn**

* Pick the right DBAPI driver and URL for each database (sync + async)
* SQLite gotchas (threads, WAL, file vs memory)
* Production-ready Postgres/MySQL engine configuration
* Connection pooling knobs (size, overflow, recycle, pre-ping) and when to change them
* Patterns for FastAPI/Flask (per-request sessions) and serverless environments

---

## 15.2 Database URLs (cheatsheet)

| DB              | Driver (sync)         | URL example (sync)                                | Driver (async)     | URL example (async)                               |
| --------------- | --------------------- | ------------------------------------------------- | ------------------ | ------------------------------------------------- |
| SQLite (file)   | built-in              | `sqlite:///./app.db`                              | aiosqlite          | `sqlite+aiosqlite:///./app.db`                    |
| SQLite (memory) | built-in              | `sqlite:///:memory:`                              | aiosqlite          | `sqlite+aiosqlite:///:memory:`                    |
| PostgreSQL      | psycopg (v3)          | `postgresql+psycopg://user:pass@host:5432/dbname` | asyncpg            | `postgresql+asyncpg://user:pass@host:5432/dbname` |
| MySQL           | pymysql / mysqlclient | `mysql+pymysql://user:pass@host:3306/dbname`      | asyncmy / aiomysql | `mysql+asyncmy://user:pass@host:3306/dbname`      |

> Tip: keep credentials in environment variables. Never hardcode.

```bash
# .env
DATABASE_URL="postgresql+psycopg://app:secret@db:5432/appdb"
ASYNC_DATABASE_URL="postgresql+asyncpg://app:secret@db:5432/appdb"
```

---

## 15.3 SQLite (local testing & small tools)

SQLite is fantastic for demos, tests, CLIs, and small single-user apps.

### 15.3.1 Engines

**Synchronous**

```python
from sqlalchemy import create_engine
engine = create_engine(
    "sqlite:///./app.db",
    echo=False,
    future=True
)
```

**In-memory (single connection only)**

```python
engine = create_engine("sqlite:///:memory:", future=True)
```

**In-memory shared across threads (tests)**

```python
from sqlalchemy.pool import StaticPool
engine = create_engine(
    "sqlite://",
    connect_args={"check_same_thread": False},
    poolclass=StaticPool,     # single in-memory DB shared by all conns
    future=True,
)
```

### 15.3.2 Threading & `check_same_thread`

* Default SQLite driver forbids using a connection in a different thread.
* For test suites or frameworks that spawn threads, pass `connect_args={"check_same_thread": False}` and ensure you manage sessions carefully.

### 15.3.3 Performance tip: WAL mode

```python
with engine.begin() as conn:
    conn.exec_driver_sql("PRAGMA journal_mode=WAL;")
    conn.exec_driver_sql("PRAGMA synchronous=NORMAL;")
```

* WAL helps concurrent readers; still not a replacement for a true server DB.

### 15.3.4 Async with SQLite (aiosqlite)

```python
from sqlalchemy.ext.asyncio import create_async_engine
async_engine = create_async_engine(
    "sqlite+aiosqlite:///./app.db",
    future=True
)
```

---

## 15.4 PostgreSQL (production-ready defaults)

**Install**: `pip install "sqlalchemy[postgresql]" psycopg[binary]`
(Or build from source for better perf: `psycopg[c]`.)

### 15.4.1 Sync engine (psycopg v3)

```python
from sqlalchemy import create_engine
engine = create_engine(
    "postgresql+psycopg://app:secret@localhost:5432/appdb",
    pool_size=10,             # typical web worker default
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,        # recycle stale conns (seconds)
    pool_pre_ping=True,       # auto-drop dead conns
    echo=False,
    future=True
)
```

### 15.4.2 Async engine (asyncpg)

```python
from sqlalchemy.ext.asyncio import create_async_engine
async_engine = create_async_engine(
    "postgresql+asyncpg://app:secret@localhost:5432/appdb",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    future=True
)
```

### 15.4.3 SSL, timeouts, search_path

```python
engine = create_engine(
    "postgresql+psycopg://app:secret@db:5432/appdb",
    connect_args={
        "sslmode": "require",      # or "verify-full" with sslrootcert
        # "sslrootcert": "/path/ca.pem"
        "connect_timeout": 10
    }
)

# Set default schema(s)
from sqlalchemy import text
with engine.begin() as conn:
    conn.execute(text("SET search_path TO app,public"))
```

---

## 15.5 MySQL / MariaDB

**Install (one of):**

* `pip install "sqlalchemy[mysql]" pymysql`
* `pip install mysqlclient` (C client; faster but needs dev headers)
* Async: `pip install asyncmy` or `aiomysql`

### 15.5.1 Sync engine (PyMySQL)

```python
from sqlalchemy import create_engine
engine = create_engine(
    "mysql+pymysql://app:secret@localhost:3306/appdb",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=3600,     # MySQL often needs recycle to avoid server closes
    pool_pre_ping=True,
    isolation_level="READ COMMITTED",  # optional
    future=True
)
```

### 15.5.2 Async engine (asyncmy)

```python
from sqlalchemy.ext.asyncio import create_async_engine
async_engine = create_async_engine(
    "mysql+asyncmy://app:secret@localhost:3306/appdb",
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=3600,
    pool_pre_ping=True,
    future=True
)
```

### 15.5.3 Character sets & SQL modes

```python
engine = create_engine(
    "mysql+pymysql://app:secret@localhost/appdb?charset=utf8mb4",
)
with engine.begin() as conn:
    conn.exec_driver_sql("SET sql_mode = 'STRICT_ALL_TABLES'")
```

---

## 15.6 Connection Pooling (how to think about it)

**Pool types**

* **QueuePool (default)**: fixed `pool_size`, can borrow up to `max_overflow` extras.
* **NullPool**: no pooling (new connection per use). Good for serverless/Lambda or when connections are extremely short-lived.
* **StaticPool**: one connection shared (mostly for SQLite in-memory tests).

**Key knobs**

* `pool_size`: steady concurrency (per process). Start with 5–10 for web apps.
* `max_overflow`: burst capacity. Start with 10–20.
* `pool_timeout`: wait time for a free connection (seconds) before raising.
* `pool_recycle`: close/reconnect after N seconds to avoid “server closed the connection”.
* `pool_pre_ping=True`: validates a connection before using (prevents “broken pipe” errors).

**Choosing values**

* Gunicorn/Uvicorn: **connections ≈ workers × expected concurrent DB usage per worker**. Keep a small buffer in `max_overflow`. Watch DB’s `max_connections`.
* Serverless (AWS Lambda, Cloud Run with heavy scale-to-zero): use **NullPool** or a very small pool; consider a connection proxy (e.g., RDS Proxy).

**Examples**

*Production web (typical):*

```python
engine = create_engine(
    DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True,
    pool_recycle=1800,
    pool_timeout=30,
)
```

*Serverless/function:*

```python
from sqlalchemy.pool import NullPool
engine = create_engine(DATABASE_URL, poolclass=NullPool)
```

*SQLite in tests (single in-memory DB):*

```python
from sqlalchemy.pool import StaticPool
engine = create_engine("sqlite://", poolclass=StaticPool, connect_args={"check_same_thread": False})
```

---

## 15.7 Sessions in Web Frameworks (sync & async)

### 15.7.1 FastAPI (sync engine, per-request session)

```python
# db.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine(DATABASE_URL, pool_pre_ping=True, future=True)
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False, future=True)

# deps.py
from contextlib import contextmanager
@contextmanager
def get_db():
    db = SessionLocal()
    try:
        yield db
        db.commit()
    except:
        db.rollback()
        raise
    finally:
        db.close()
```

```python
# routes.py
from fastapi import Depends, FastAPI
from .deps import get_db
app = FastAPI()

@app.get("/users/{user_id}")
def read_user(user_id: int, db=Depends(get_db)):
    return db.get(User, user_id)
```

### 15.7.2 FastAPI (async engine + AsyncSession)

```python
# db_async.py
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession

async_engine = create_async_engine(ASYNC_DATABASE_URL, pool_pre_ping=True, future=True)
AsyncSessionLocal = async_sessionmaker(async_engine, expire_on_commit=False, autoflush=False)

async def get_async_db() -> AsyncSession:
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except:
            await session.rollback()
            raise
```

### 15.7.3 Flask (sync)

```python
# app.py
from flask import Flask, g
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine(DATABASE_URL, pool_pre_ping=True, future=True)
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False, future=True)

app = Flask(__name__)

@app.before_request
def open_session():
    g.db = SessionLocal()

@app.teardown_request
def close_session(exc):
    try:
        if exc:
            g.db.rollback()
        else:
            g.db.commit()
    finally:
        g.db.close()
```

---

## 15.8 Migrations & URLs (quick glue)

**Alembic `env.py`** often reads from env var:

```python
import os
from sqlalchemy import engine_from_config, pool
from alembic import context

config = context.config
config.set_main_option("sqlalchemy.url", os.environ["DATABASE_URL"])
```

**SQLite special note**: migrations that alter columns are limited; when targeting Postgres/MySQL in prod, **develop against the same engine** locally or run a CI job against Postgres/MySQL to catch differences.

---

## 15.9 Docker & Compose (handy starter)

```yaml
# docker-compose.yml
services:
  db:
    image: postgres:16
    environment:
      POSTGRES_DB: appdb
      POSTGRES_USER: app
      POSTGRES_PASSWORD: secret
    ports: ["5432:5432"]
    volumes: [pgdata:/var/lib/postgresql/data]
  app:
    build: .
    environment:
      DATABASE_URL: postgresql+psycopg://app:secret@db:5432/appdb
    depends_on: [db]
volumes:
  pgdata:
```

---

## 15.10 Troubleshooting (fast fixes)

* **`OperationalError: server closed the connection`** → set `pool_pre_ping=True`, tune `pool_recycle`, check DB idle timeouts.
* **“Too many connections”** → reduce `pool_size`/`max_overflow`, verify worker counts, use a proxy (RDS Proxy/pgBouncer).
* **SQLite “database is locked”** → prefer WAL, reduce long transactions, don’t share one connection across threads.
* **SSL errors** → check `sslmode` and CA bundle path; cloud DBs often require `require/verify-full`.

---

## 15.11 Checklists

**Local dev**

* [ ] Start with SQLite file DB (`sqlite:///./app.db`)
* [ ] Enable `WAL` mode for concurrent reads
* [ ] Seed via Alembic or fixtures

**Staging/Prod (Postgres/MySQL)**

* [ ] Use env-driven URLs
* [ ] `pool_pre_ping=True`, `pool_recycle` (1800–3600s)
* [ ] Right-size `pool_size` & `max_overflow` to app concurrency
* [ ] Health probes for DB availability
* [ ] CI runs migrations against the same engine family

---

## 15.12 Mini-lab

1. Start Postgres locally (Docker compose above).
2. Set `DATABASE_URL`.
3. Create engine and run a simple transaction:

```python
from sqlalchemy import create_engine, text
engine = create_engine(DATABASE_URL, pool_pre_ping=True, future=True)
with engine.begin() as conn:
    conn.execute(text("CREATE TABLE IF NOT EXISTS ping (id serial PRIMARY KEY, ts timestamptz default now())"))
    conn.execute(text("INSERT INTO ping DEFAULT VALUES"))
    print(conn.execute(text("SELECT count(*) FROM ping")).scalar_one())
```

4. Switch to async engine and repeat using `create_async_engine`.

---

### Wrap-up

You now have copy-paste-able, production-savvy configs for SQLite, Postgres, and MySQL—plus the mental model for connection pools and the per-request session pattern you’ll use in real apps. In the next chapter, we’ll integrate with web frameworks end-to-end (routers, DTOs, and dependency injection).

